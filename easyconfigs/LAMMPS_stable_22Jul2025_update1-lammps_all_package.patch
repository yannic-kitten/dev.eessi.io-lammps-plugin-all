diff --git a/cmake/CMakeLists.txt b/cmake/CMakeLists.txt
index da65dbb5ff..3cd888b128 100644
--- a/cmake/CMakeLists.txt
+++ b/cmake/CMakeLists.txt
@@ -261,6 +261,7 @@ option(CMAKE_VERBOSE_MAKEFILE "Generate verbose Makefiles" OFF)
 
 set(STANDARD_PACKAGES
   ADIOS
+  ALLPKG
   AMOEBA
   APIP
   ASPHERE
@@ -442,6 +443,7 @@ pkg_depends(ML-IAP ML-SNAP)
 pkg_depends(ATC MANYBODY)
 pkg_depends(LATBOLTZ MPI)
 pkg_depends(SCAFACOS MPI)
+pkg_depends(ALLPKG MPI)
 pkg_depends(AMOEBA KSPACE)
 pkg_depends(DIELECTRIC KSPACE)
 pkg_depends(DIELECTRIC EXTRA-PAIR)
@@ -591,7 +593,7 @@ else()
 endif()
 
 foreach(PKG_WITH_INCL KSPACE PYTHON ML-IAP VORONOI COLVARS ML-HDNNP MDI MOLFILE NETCDF
-        PLUMED QMMM ML-QUIP SCAFACOS MACHDYN VTK KIM COMPRESS ML-PACE LEPTON EXTRA-COMMAND)
+        PLUMED QMMM ML-QUIP SCAFACOS MACHDYN VTK KIM COMPRESS ML-PACE LEPTON EXTRA-COMMAND ALLPKG)
   if(PKG_${PKG_WITH_INCL})
     include(Packages/${PKG_WITH_INCL})
   endif()
diff --git a/cmake/Modules/Packages/ALLPKG.cmake b/cmake/Modules/Packages/ALLPKG.cmake
new file mode 100644
index 0000000000..77fc6fd310
--- /dev/null
+++ b/cmake/Modules/Packages/ALLPKG.cmake
@@ -0,0 +1,40 @@
+# find required packages
+find_package(MPI REQUIRED)
+
+# try to find ALL
+set(DOWNLOAD_ALLPKG_DEFAULT ON)
+find_package(ALL QUIET)
+if(ALL_FOUND)
+  set(DOWNLOAD_ALLPKG_DEFAULT OFF)
+endif()
+
+option(DOWNLOAD_ALLPKG "Download ALL library instead of using an already installed one" ${DOWNLOAD_ALLPKG_DEFAULT})
+if(DOWNLOAD_ALLPKG)
+  # Download ALL and integrate it into the build process
+  message(STATUS "ALL download requested - we will build our own")
+  set(ALL_URL "https://gitlab.jsc.fz-juelich.de/SLMS/loadbalancing/-/archive/v0.9.3/loadbalancing-v0.9.3.tar.gz" CACHE STRING "URL for ALL tarball")
+  set(ALL_MD5 "9fc008711a7dfaf35e957411f8ed1504" CACHE STRING "MD5 checksum of ALL tarball")
+  mark_as_advanced(ALL_URL)
+  mark_as_advanced(ALL_MD5)
+  GetFallbackURL(ALL_URL ALL_FALLBACK)
+
+  include(ExternalProject)
+  ExternalProject_Add(ALL_build
+    URL     ${ALL_URL} ${ALL_FALLBACK}
+    URL_MD5 ${ALL_MD5}
+    CMAKE_ARGS
+      -DCMAKE_INSTALL_PREFIX=<INSTALL_DIR>
+      -DCMAKE_INSTALL_LIBDIR=lib
+  )
+
+  ExternalProject_get_property(ALL_build INSTALL_DIR)
+  file(MAKE_DIRECTORY ${INSTALL_DIR}/include)
+  add_library(LAMMPS::ALL INTERFACE IMPORTED)
+  add_dependencies(LAMMPS::ALL ALL_build)
+  set_target_properties(LAMMPS::ALL PROPERTIES INTERFACE_INCLUDE_DIRECTORIES "${INSTALL_DIR}/include")
+  target_link_libraries(lammps PRIVATE LAMMPS::ALL)
+else()
+  # link found ALL library
+  find_package(ALL REQUIRED)
+  target_link_libraries(lammps PRIVATE ALL::ALL)
+endif()
diff --git a/cmake/presets/all_off.cmake b/cmake/presets/all_off.cmake
index 9c76e892fe..6ce32727e1 100644
--- a/cmake/presets/all_off.cmake
+++ b/cmake/presets/all_off.cmake
@@ -3,6 +3,7 @@
 
 set(ALL_PACKAGES
   ADIOS
+  ALLPKG
   AMOEBA
   APIP
   ASPHERE
diff --git a/cmake/presets/all_on.cmake b/cmake/presets/all_on.cmake
index ba9474840a..30840c9617 100644
--- a/cmake/presets/all_on.cmake
+++ b/cmake/presets/all_on.cmake
@@ -5,6 +5,7 @@
 
 set(ALL_PACKAGES
   ADIOS
+  ALLPKG
   AMOEBA
   APIP
   ASPHERE
diff --git a/cmake/presets/download.cmake b/cmake/presets/download.cmake
index d10214ca65..3053201843 100644
--- a/cmake/presets/download.cmake
+++ b/cmake/presets/download.cmake
@@ -1,7 +1,7 @@
 # Preset that turns on packages with automatic downloads of sources or potentials.
 # Compilation of libraries like Plumed or ScaFaCoS can take a considerable amount of time.
 
-set(ALL_PACKAGES KIM MSCG VORONOI PLUMED SCAFACOS MACHDYN MESONT MDI ML-PACE)
+set(ALL_PACKAGES KIM MSCG VORONOI PLUMED SCAFACOS ALLPKG MACHDYN MESONT MDI ML-PACE)
 
 foreach(PKG ${ALL_PACKAGES})
   set(PKG_${PKG} ON CACHE BOOL "" FORCE)
@@ -14,4 +14,5 @@ set(DOWNLOAD_EIGEN3 ON CACHE BOOL "" FORCE)
 set(DOWNLOAD_PACE ON CACHE BOOL "" FORCE)
 set(DOWNLOAD_PLUMED ON CACHE BOOL "" FORCE)
 set(DOWNLOAD_SCAFACOS ON CACHE BOOL "" FORCE)
+set(DOWNLOAD_ALLPKG ON CACHE BOOL "" FORCE)
 
diff --git a/cmake/presets/nolib.cmake b/cmake/presets/nolib.cmake
index 269aed33ed..d79b296638 100644
--- a/cmake/presets/nolib.cmake
+++ b/cmake/presets/nolib.cmake
@@ -3,6 +3,7 @@
 
 set(PACKAGES_WITH_LIB
   ADIOS
+  ALLPKG
   APIP
   ATC
   AWPMD
diff --git a/examples/PACKAGES/allpkg/README b/examples/PACKAGES/allpkg/README
new file mode 100644
index 0000000000..3c7a90c9b3
--- /dev/null
+++ b/examples/PACKAGES/allpkg/README
@@ -0,0 +1,8 @@
+The `balance/all` fix is more or less a drop-in replacement for the `balance` fix provided by LAMMPS.
+
+It supports two main decomposition methods 'staggered' and 'tensor'.
+The 'tensor' decomposition exists in two variants, one minimizing the average load of the system ('tensor classic') and one minimizing the maximal load of the system ('tensor max').
+
+For staggered decomposition you can choose to balance locally or globally (aka Histogram), while tensor decomposition only supports local balancing.
+
+Just like `balance`, `balance/all` supports all the `weight` options.
diff --git a/examples/PACKAGES/allpkg/in.balance.2d b/examples/PACKAGES/allpkg/in.balance.2d
new file mode 100644
index 0000000000..16efbacd04
--- /dev/null
+++ b/examples/PACKAGES/allpkg/in.balance.2d
@@ -0,0 +1,64 @@
+# 2d circle of particles inside a box with LJ walls (same like in examples/balance/in.balance)
+
+variable	b index 0
+
+variable	x index 50
+variable	y index 20
+variable	d index 20
+variable	v index 5
+variable	w index 2
+
+units		lj
+dimension	2
+atom_style	atomic
+boundary	f f p
+
+lattice		hex 0.85
+region		box block 0 $x 0 $y -0.5 0.5
+create_box	1 box
+region		circle sphere $(v_d/2+1) $(v_d/2/sqrt(3.0)+1) 0.0 $(v_d/2)
+create_atoms	1 region circle
+mass		1 1.0
+
+velocity	all create 0.5 87287 loop geom
+velocity        all set $v $w 0 sum yes
+
+pair_style	lj/cut 2.5
+pair_coeff	1 1 10.0 1.0 2.5
+
+neighbor	0.3 bin
+neigh_modify	delay 0 every 1 check yes
+
+fix		1 all nve
+
+fix		2 all wall/lj93 xlo 0.0 1 1 2.5 xhi $x 1 1 2.5
+fix		3 all wall/lj93 ylo 0.0 1 1 2.5 yhi $y 1 1 2.5
+
+
+comm_style	staggered zyx # zyx is hard coded for historic reasons (we discussed a variable order of cuts in the past, but then never implemented them in ALL afaik)
+fix		5 all balance/all every 50 grid staggered global 0.9 0.003
+#fix		5 all balance/all every 50 grid staggered weight time 1.0 weight neigh 0.5 global 0.9 0.003 true
+##fix		5 all balance/all every 50 grid staggered load natoms global 0.9 0.003 true
+
+#comm_style	tiled
+#fix		5 all balance 50 0.9 rcb
+
+#comm_style	brick
+#fix		5 all balance/all every 50 grid tensor max weight time 1.0 local 0.9
+##fix		5 all balance/all every 50 grid tensor max load natoms local 0.9
+
+#comm_style	staggered zyx
+#fix		5 all balance/all every 50 grid staggered weight time 1.0 local 1.2 global 1.5 0.003 true
+##fix		5 all balance/all every 50 grid staggered load natoms local 1.2 global 1.5 0.003 true
+
+
+compute		1 all property/atom proc
+variable	p atom c_1%10
+dump		2 all custom 50 /tmp/tmp.dump id v_p x y z
+
+log         balance_all.log
+
+thermo_style	custom step temp epair press f_5[*]
+thermo		100
+
+run		10000
diff --git a/examples/PACKAGES/allpkg/in.balance.staggered.global b/examples/PACKAGES/allpkg/in.balance.staggered.global
new file mode 100644
index 0000000000..8fc88da23f
--- /dev/null
+++ b/examples/PACKAGES/allpkg/in.balance.staggered.global
@@ -0,0 +1,51 @@
+# 2d circle of particles inside a box with LJ walls (based off examples/balance/in.balance)
+
+variable        b index 0
+
+variable        x index 50
+variable        y index 20
+variable        d index 20
+variable        v index 5
+variable        w index 2
+
+units           lj
+dimension       2
+atom_style      atomic
+boundary        f f p
+
+lattice         hex 0.85
+region          box block 0 $x 0 $y -0.5 0.5
+create_box      1 box
+region          circle sphere $(v_d/2+1) $(v_d/2/sqrt(3.0)+1) 0.0 $(v_d/2)
+create_atoms    1 region circle
+mass            1 1.0
+
+velocity        all create 0.5 87287 loop geom
+velocity        all set $v $w 0 sum yes
+
+pair_style      lj/cut 2.5
+pair_coeff      1 1 10.0 1.0 2.5
+
+neighbor        0.3 bin
+neigh_modify    delay 0 every 1 check yes
+
+fix             1 all nve
+
+fix             2 all wall/lj93 xlo 0.0 1 1 2.5 xhi $x 1 1 2.5
+fix             3 all wall/lj93 ylo 0.0 1 1 2.5 yhi $y 1 1 2.5
+
+
+comm_style      staggered zyx # zyx is hard coded for historic reasons (a variable order of cuts has been discussed but not yet implemented in ALL)
+fix             5 all balance/all every 50 grid staggered global 0.9 0.003
+
+#compute         1 all property/atom proc
+#variable        p atom c_1%10
+#dump            2 all custom 50 /tmp/tmp.dump id v_p x y z
+#
+#log             balance_all.log
+
+thermo_style    custom step temp epair press f_5[*]
+thermo          100
+
+run             10000
+
diff --git a/examples/PACKAGES/allpkg/in.balance.staggered.local b/examples/PACKAGES/allpkg/in.balance.staggered.local
new file mode 100644
index 0000000000..0ab4187054
--- /dev/null
+++ b/examples/PACKAGES/allpkg/in.balance.staggered.local
@@ -0,0 +1,51 @@
+# 2d circle of particles inside a box with LJ walls (based off examples/balance/in.balance)
+
+variable        b index 0
+
+variable        x index 50
+variable        y index 20
+variable        d index 20
+variable        v index 5
+variable        w index 2
+
+units           lj
+dimension       2
+atom_style      atomic
+boundary        f f p
+
+lattice         hex 0.85
+region          box block 0 $x 0 $y -0.5 0.5
+create_box      1 box
+region          circle sphere $(v_d/2+1) $(v_d/2/sqrt(3.0)+1) 0.0 $(v_d/2)
+create_atoms    1 region circle
+mass            1 1.0
+
+velocity        all create 0.5 87287 loop geom
+velocity        all set $v $w 0 sum yes
+
+pair_style      lj/cut 2.5
+pair_coeff      1 1 10.0 1.0 2.5
+
+neighbor        0.3 bin
+neigh_modify    delay 0 every 1 check yes
+
+fix             1 all nve
+
+fix             2 all wall/lj93 xlo 0.0 1 1 2.5 xhi $x 1 1 2.5
+fix             3 all wall/lj93 ylo 0.0 1 1 2.5 yhi $y 1 1 2.5
+
+
+comm_style      staggered zyx # zyx is hard coded for historic reasons (a variable order of cuts has been discussed but not yet implemented in ALL)
+fix             5 all balance/all every 50 grid staggered local 0.9
+
+#compute         1 all property/atom proc
+#variable        p atom c_1%10
+#dump            2 all custom 50 /tmp/tmp.dump id v_p x y z
+#
+#log             balance_all.log
+
+thermo_style    custom step temp epair press f_5[*]
+thermo          100
+
+run             10000
+
diff --git a/examples/PACKAGES/allpkg/in.balance.tensor.classic b/examples/PACKAGES/allpkg/in.balance.tensor.classic
new file mode 100644
index 0000000000..469a42a09a
--- /dev/null
+++ b/examples/PACKAGES/allpkg/in.balance.tensor.classic
@@ -0,0 +1,51 @@
+# 2d circle of particles inside a box with LJ walls (based off examples/balance/in.balance)
+
+variable        b index 0
+
+variable        x index 50
+variable        y index 20
+variable        d index 20
+variable        v index 5
+variable        w index 2
+
+units           lj
+dimension       2
+atom_style      atomic
+boundary        f f p
+
+lattice         hex 0.85
+region          box block 0 $x 0 $y -0.5 0.5
+create_box      1 box
+region          circle sphere $(v_d/2+1) $(v_d/2/sqrt(3.0)+1) 0.0 $(v_d/2)
+create_atoms    1 region circle
+mass            1 1.0
+
+velocity        all create 0.5 87287 loop geom
+velocity        all set $v $w 0 sum yes
+
+pair_style      lj/cut 2.5
+pair_coeff      1 1 10.0 1.0 2.5
+
+neighbor        0.3 bin
+neigh_modify    delay 0 every 1 check yes
+
+fix             1 all nve
+
+fix             2 all wall/lj93 xlo 0.0 1 1 2.5 xhi $x 1 1 2.5
+fix             3 all wall/lj93 ylo 0.0 1 1 2.5 yhi $y 1 1 2.5
+
+
+comm_style      brick
+fix             5 all balance/all every 50 grid tensor classic local 0.9
+
+#compute         1 all property/atom proc
+#variable        p atom c_1%10
+#dump            2 all custom 50 /tmp/tmp.dump id v_p x y z
+#
+#log             balance_all.log
+
+thermo_style    custom step temp epair press f_5[*]
+thermo          100
+
+run             10000
+
diff --git a/examples/PACKAGES/allpkg/in.balance.tensor.max b/examples/PACKAGES/allpkg/in.balance.tensor.max
new file mode 100644
index 0000000000..398a8fc8eb
--- /dev/null
+++ b/examples/PACKAGES/allpkg/in.balance.tensor.max
@@ -0,0 +1,51 @@
+# 2d circle of particles inside a box with LJ walls (based off examples/balance/in.balance)
+
+variable        b index 0
+
+variable        x index 50
+variable        y index 20
+variable        d index 20
+variable        v index 5
+variable        w index 2
+
+units           lj
+dimension       2
+atom_style      atomic
+boundary        f f p
+
+lattice         hex 0.85
+region          box block 0 $x 0 $y -0.5 0.5
+create_box      1 box
+region          circle sphere $(v_d/2+1) $(v_d/2/sqrt(3.0)+1) 0.0 $(v_d/2)
+create_atoms    1 region circle
+mass            1 1.0
+
+velocity        all create 0.5 87287 loop geom
+velocity        all set $v $w 0 sum yes
+
+pair_style      lj/cut 2.5
+pair_coeff      1 1 10.0 1.0 2.5
+
+neighbor        0.3 bin
+neigh_modify    delay 0 every 1 check yes
+
+fix             1 all nve
+
+fix             2 all wall/lj93 xlo 0.0 1 1 2.5 xhi $x 1 1 2.5
+fix             3 all wall/lj93 ylo 0.0 1 1 2.5 yhi $y 1 1 2.5
+
+
+comm_style      brick
+fix             5 all balance/all every 50 grid tensor max local 0.9
+
+#compute         1 all property/atom proc
+#variable        p atom c_1%10
+#dump            2 all custom 50 /tmp/tmp.dump id v_p x y z
+#
+#log             balance_all.log
+
+thermo_style    custom step temp epair press f_5[*]
+thermo          100
+
+run             10000
+
diff --git a/lib/allpkg/.gitignore b/lib/allpkg/.gitignore
new file mode 100644
index 0000000000..d462f934ee
--- /dev/null
+++ b/lib/allpkg/.gitignore
@@ -0,0 +1,4 @@
+/loadbalancing*
+/include
+/lib
+/build
diff --git a/lib/allpkg/Install.py b/lib/allpkg/Install.py
new file mode 100755
index 0000000000..f3590c96db
--- /dev/null
+++ b/lib/allpkg/Install.py
@@ -0,0 +1,132 @@
+#!/usr/bin/env python
+
+"""
+Install.py tool to download, unpack, build, and link to the ALL library
+used to automate the steps described in the README file in this dir
+"""
+
+from __future__ import print_function
+import sys, os, subprocess, shutil, tarfile
+from argparse import ArgumentParser
+
+sys.path.append('..')
+from install_helpers import fullpath, geturl, get_cpus, checkmd5sum, getfallback
+
+parser = ArgumentParser(prog='Install.py', description="LAMMPS library build wrapper script")
+
+# settings
+
+version = "0.9.3"
+
+# known md5 checksums for different ALL versions. used to validate the download.
+checksums = {
+        '0.9.2' : '2fcc8bcb60f33fa0369e8f44a5c4b884',
+        '0.9.3' : '9fc008711a7dfaf35e957411f8ed1504'
+        }
+
+# extra help message
+
+HELP = """
+Syntax from src dir: make lib-allpkg args="-b"
+                 or: make lib-allpkg args="-p /path/to/ALL"
+Syntax from lib dir: python Install.py -b
+                 or: python Install.py -p /path/to/ALL
+
+Example:
+
+make lib-allpkg args="-b"   # download/build in lib/allpkg/ALL
+make lib-allpkg args="-p $HOME/ALL" # use existing ALL installation in $HOME
+"""
+
+# parse and process arguments
+
+pgroup = parser.add_mutually_exclusive_group()
+pgroup.add_argument("-b", "--build", action="store_true",
+                    help="download and build the ALL library")
+pgroup.add_argument("-p", "--path",
+                    help="specify folder of existing ALL installation")
+parser.add_argument("-v", "--version", default=version,
+                    help="set version of ALL to download and build (default: %s)" % version)
+
+args = parser.parse_args()
+
+# print help message and exit, if neither build nor path options are given
+if not args.build and not args.path:
+  parser.print_help()
+  sys.exit(HELP)
+
+buildflag = args.build
+pathflag = args.path is not None
+version = args.version
+url = "https://gitlab.jsc.fz-juelich.de/SLMS/loadbalancing/-/archive/v%s/loadbalancing-v%s.tar.gz" % (version, version)
+
+
+homepath = fullpath(".")
+ALL_path = os.path.join(homepath, "loadbalancing-v%s" % version)
+
+if pathflag:
+  ALL_path = args.path
+  if not os.path.isdir(os.path.join(ALL_path, "include")):
+    sys.exit("ALL include path for %s does not exist" % ALL_path)
+  if (not os.path.isdir(os.path.join(ALL_path, "lib64"))) \
+     and (not os.path.isdir(os.path.join(ALL_path, "lib"))):
+    sys.exit("ALL lib path for %s does not exist" % ALL_path)
+  ALL_path = fullpath(ALL_path)
+
+# download and unpack ALL tarball
+
+if buildflag:
+  print("Downloading ALL ...")
+  filename = "%s/loadbalancing-v%s.tar.gz" % (homepath, version)
+  fallback = getfallback('loadbalancing', url)
+  try:
+    geturl(url, filename)
+  except:
+    geturl(fallback, filename)
+
+  # verify downloaded archive integrity via md5 checksum, if known.
+  if version in checksums:
+    if not checkmd5sum(checksums[version], filename):
+      print("Checksum did not match. Trying fallback URL", fallback)
+      geturl(fallback, filename)
+      if not checkmd5sum(checksums[version], filename):
+        sys.exit("Checksum for ALL library does not match for fallback, too.")
+
+  print("Unpacking ALL tarball ...")
+  if os.path.exists(ALL_path):
+    shutil.rmtree(ALL_path)
+  tarname = os.path.join(homepath, "%s.tar.gz" % ALL_path)
+  if tarfile.is_tarfile(tarname):
+    tgz = tarfile.open(tarname)
+    tgz.extractall(path=homepath)
+    os.remove(tarname)
+  else:
+    sys.exit("File %s is not a supported archive" % tarname)
+
+  # build ALL
+  print("Building ALL ...")
+  n_cpu = get_cpus()
+  build_dir = os.path.join(homepath, 'build')
+  cmd = 'gotoCleanDir() { test -d $1 && rm -r $1 ; mkdir -p $1 ; cd $1 ; } ; gotoCleanDir "%s" ; cmake "%s" ; cmake --build ./ --parallel "%d" && cmake --install ./ --prefix ./' % (build_dir, ALL_path, n_cpu)
+  try:
+    txt = subprocess.check_output(cmd, stderr=subprocess.STDOUT, shell=True)
+    print(txt.decode('UTF-8'))
+  except subprocess.CalledProcessError as e:
+    sys.exit("CMake failed with:\n %s" % e.output.decode('UTF-8'))
+
+# create 2 links in lib/allpkg to ALL include/lib dirs
+
+print("Creating links to ALL include and lib files")
+if os.path.isfile("include") or os.path.islink("include"):
+  os.remove("include")
+if os.path.isfile("lib") or os.path.islink("lib"):
+  os.remove("lib")
+if buildflag:
+  os.symlink(os.path.join(homepath, 'build', 'include'), 'include')
+  os.symlink(os.path.join(homepath, 'build', 'lib'), 'lib')
+else:
+  os.symlink(os.path.join(ALL_path, 'include'), 'include')
+  if os.path.isdir(os.path.join(ALL_path, "lib64")):
+    os.symlink(os.path.join(ALL_path, 'lib64'), 'lib')
+  else:
+    os.symlink(os.path.join(ALL_path, 'lib'), 'lib')
diff --git a/lib/allpkg/README b/lib/allpkg/README
new file mode 100644
index 0000000000..e83eafd1fd
--- /dev/null
+++ b/lib/allpkg/README
@@ -0,0 +1,42 @@
+A Load Balancing Library (ALL):
+
+-----------------
+
+The library aims to provide an easy way to include dynamic domain-based
+load balancing into particle based simulation codes. The library is
+developed in the Simulation Laboratory Molecular Systems of the Jülich
+Supercomputing Centre at Forschungszentrum Jülich. 
+
+-----------------
+
+Requirements:
+    Base:
+        - C++11 capable compiler
+        - MPI support
+        - CMake v. 3.14 or higher
+    Optional:
+        - Fortran 2003 capable compiler (Fortran interface)
+        - Fortran 2008 capable compiler (Usage of the `mpi_f08` interface)
+        - VTK 7.1 or higher (Domain output)
+        - Boost testing utilities
+        - Doxygen and Sphinx with `breathe` (Documentation)
+
+-----------------
+
+Installation:
+
+    1.) Clone the library from https://gitlab.jsc.fz-juelich.de/SLMS/loadbalancing
+        into `$ALL_ROOT_DIR`.
+    2.) Create the build directory `$ALL_BUILD_DIR` some place else.
+    3.) Call 
+            cmake -S "$ALL_ROOT_DIR" -B "$ALL_BUILD_DIR"
+        to set up the installation.
+        To use a specific compiler and Boost installation use:
+            CC=gcc CXX=g++ BOOST_ROOT=$BOOST_DIR cmake [...]
+    4.) To build and install the library then run:
+            cmake --build "$ALL_BUILD_DIR"
+            cmake --install "$ALL_BUILD_DIR" --prefix "$ALL_INSTALL_DIR"
+        Afterwards, the built examples and library files are placed in
+        `$ALL_INSTALL_DIR`.
+
+-----------------
diff --git a/src/ALLPKG/Install.sh b/src/ALLPKG/Install.sh
new file mode 100644
index 0000000000..024bcf31fa
--- /dev/null
+++ b/src/ALLPKG/Install.sh
@@ -0,0 +1,64 @@
+# Install/unInstall package files in LAMMPS
+# mode = 0/1/2 for uninstall/install/update
+
+mode=$1
+
+# enforce using portable C locale
+LC_ALL=C
+export LC_ALL
+
+# arg1 = file, arg2 = file it depends on
+
+action () {
+  if (test $mode = 0) then
+    rm -f ../$1
+  elif (! cmp -s $1 ../$1) then
+    if (test -z "$2" || test -e ../$2) then
+      cp $1 ..
+      if (test $mode = 2) then
+        echo "  updating src/$1"
+      fi
+    fi
+  elif (test -n "$2") then
+    if (test ! -e ../$2) then
+      rm -f ../$1
+    fi
+  fi
+}
+
+# list of package files with otional dependencies
+
+action fix_balance_all.h
+action fix_balance_all.cpp
+
+# edit 2 Makefile.package files to include/exclude package info
+
+if (test $1 = 1) then
+
+  if (test -e ../Makefile.package) then
+    sed -i -e 's/[^ \t]*allpkg[^ \t]* //' ../Makefile.package
+    sed -i -e 's|^PKG_SYSINC =[ \t]*|&$(allpkg_SYSINC) |' ../Makefile.package
+    sed -i -e 's|^PKG_SYSLIB =[ \t]*|&$(allpkg_SYSLIB) |' ../Makefile.package
+    sed -i -e 's|^PKG_SYSPATH =[ \t]*|&$(allpkg_SYSPATH) |' ../Makefile.package
+  fi
+
+  if (test -e ../Makefile.package.settings) then
+    sed -i -e '/^include.*allpkg.*$/d' ../Makefile.package.settings
+    # multiline form needed for BSD sed on Macs
+    sed -i -e '4 i \
+include ..\/..\/lib\/allpkg\/Makefile.lammps
+' ../Makefile.package.settings
+  fi
+
+elif (test $1 = 0) then
+
+  if (test -e ../Makefile.package) then
+    sed -i -e 's/[^ \t]*allpkg[^ \t]* //' ../Makefile.package
+  fi
+
+  if (test -e ../Makefile.package.settings) then
+    sed -i -e '/^[ \t]*include.*allpkg.*$/d' ../Makefile.package.settings
+  fi
+
+fi
+
diff --git a/src/ALLPKG/fix_balance_all.cpp b/src/ALLPKG/fix_balance_all.cpp
new file mode 100644
index 0000000000..72e446b0de
--- /dev/null
+++ b/src/ALLPKG/fix_balance_all.cpp
@@ -0,0 +1,870 @@
+/* ----------------------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+#include "fix_balance_all.h"
+
+#include "ALL.hpp"
+
+#include "timer.h"
+#include "pointers.h"
+#include "pair.h"
+#include "fix_store_atom.h"
+
+#include "atom.h"
+#include "comm.h"
+#include "domain.h"
+#include "error.h"
+#include "force.h"
+#include "group.h"
+#include "imbalance.h"
+#include "imbalance_group.h"
+#include "imbalance_neigh.h"
+#include "imbalance_store.h"
+#include "imbalance_time.h"
+#include "imbalance_var.h"
+#include "irregular.h"
+#include "kspace.h"
+#include "modify.h"
+#include "neighbor.h"
+#include "memory.h"
+#include "update.h"
+
+#include <cstring>
+#include <mpi.h>
+#include <math.h>
+
+using namespace LAMMPS_NS;
+using namespace FixConst;
+
+enum { TENSOR, STAGGERED, UNKNOWN_GRID };
+enum { TENSOR_MAX, TENSOR_CLASSIC, NONE };
+
+// clang-format off
+
+/**
+ *  create class and parse arguments in LAMMPS script.
+ *  Syntax:
+ *
+ *  fix ID group-ID balance/all keyword args ...
+ *
+ *  required keyword/arg pairs
+ *
+ *      every arg = nevery
+ *          nevery = perform dynamic load balancing every this many steps
+ *      grid style args = define grid
+ *          style = staggered or tensor
+ *              staggered args = none
+ *              tensor args = max or classic
+ *                max = use TENSOR_MAX method of ALL
+ *                classic = use TENSOR method of ALL
+ *
+ *      weight style args = use weighted particle counts for the balancing
+ *          style = group or neigh or time or var or store
+ *              group args = Ngroup group1 weight1 group2 weight2 ...
+ *                Ngroup = number of groups with assigned weights
+ *                group1, group2, ... = group IDs
+ *                weight1, weight2, ...   = corresponding weight factors
+ *              neigh factor = compute weight based on number of neighbors
+ *                factor = scaling factor (> 0)
+ *              time factor = compute weight based on time spend computing
+ *                factor = scaling factor (> 0)
+ *              var name = take weight from atom-style variable
+ *                name = name of the atom-style variable
+ *              store name = store weight in custom atom property defined by fix property/atom command
+ *                name = atom property name (without d_ prefix)
+ *
+ *  At least one of the following keyword/arg pairs is required.
+ *  Only one (or none) load balancer is used in a load balancing step.
+ *
+ *      global args = trigger_threshold bin_width (use histogram balancing; only for staggered)
+ *          trigger_threshold = float
+ *              float = apply load balancer if the imbalance of the load is above this threshold
+ *          bin_width = approximate width of bin (arbitrary positive value)
+ *      local args = trigger_threshold (use local balancing)
+ *          trigger_threshold = float
+ *              float = apply load balancer if the imbalance of the load is above this threshold
+ *
+ *  optional keyword arg pairs
+ *
+ *      verbose args = none (verbose output to log/screen)
+ */
+
+FixBalanceAll::FixBalanceAll(LAMMPS *lmp, int narg, char **arg) :
+  Fix(lmp, narg, arg), all_local(nullptr), irregular(nullptr), all_global(nullptr)
+{
+  if (narg < 6) error->all(FLERR,"Illegal fix balance/all command");
+
+  imbalances = nullptr;
+  fixstore = nullptr;
+
+  box_change = BOX_CHANGE_DOMAIN;
+  pre_exchange_migrate = 1;
+
+  vector_flag = 1;
+  size_vector = 6;
+  extvector = 0;
+
+  // parse required arguments
+
+  if (domain->triclinic) error->all(FLERR,"triclinic domains are not yet supported by ALL");
+
+  // set defaul values
+
+  gridstyle = UNKNOWN_GRID;
+  int tensorstyle = NONE;
+  nevery = -1;
+  bw = -1;
+  local_threshold = -1;
+  global_threshold = -1;
+  use_local_lb = false;
+  use_global_lb = false;
+  verbose = false;
+  wtflag = 0;
+  varflag = 0;
+
+  // count max number of weight settings
+
+  nimbalance = 0;
+  for (int i = 3; i < narg; i++)
+    if (strcmp(arg[i],"weight") == 0) nimbalance++;
+  if (nimbalance) imbalances = new Imbalance*[nimbalance];
+  nimbalance = 0;
+
+  // parse arguments
+  for (int iarg = 3; iarg < narg; ++iarg) {
+    if (strcmp(arg[iarg],"every") == 0) {
+      if (iarg+1 >= narg) error->all(FLERR, "balance/all: every requires an integer");
+      nevery = utils::inumeric(FLERR,arg[iarg+1],false,lmp);
+      iarg++;
+    } else if (strcmp(arg[iarg],"grid") == 0) {
+      if (iarg+1 >= narg) error->all(FLERR, "balance/all: grid requires one argument");
+      if (gridstyle != UNKNOWN_GRID) error->all(FLERR, "balance/all: multiple grid styles defined");
+      if (strcmp(arg[iarg+1],"staggered") == 0) gridstyle = STAGGERED;
+      else if (strcmp(arg[iarg+1],"tensor") == 0) {
+        gridstyle = TENSOR;
+        if (iarg+2 >= narg) error->all(FLERR, "balance/all: grid tensor requires one argument");
+        if (strcmp(arg[iarg+2],"classic") == 0) tensorstyle = TENSOR_CLASSIC;
+        else if (strcmp(arg[iarg+2],"max") == 0) tensorstyle = TENSOR_MAX;
+        else error->all(FLERR, "balance/all: unknown grid tensor argument {}", arg[iarg+2]);
+        iarg++;
+      } else error->all(FLERR, "balance/all: unknown grid argument {}", arg[iarg+1]);
+      iarg++;
+    } else if (strcmp(arg[iarg],"weight") == 0) {
+      wtflag = 1;
+      Imbalance *imb;
+      int nopt = 0;
+      if (strcmp(arg[iarg+1],"group") == 0) {
+        imb = new ImbalanceGroup(lmp);
+        nopt = imb->options(narg-iarg,arg+iarg+2);
+        imbalances[nimbalance++] = imb;
+      } else if (strcmp(arg[iarg+1],"time") == 0) {
+        imb = new ImbalanceTime(lmp);
+        nopt = imb->options(narg-iarg,arg+iarg+2);
+        imbalances[nimbalance++] = imb;
+      } else if (strcmp(arg[iarg+1],"neigh") == 0) {
+        imb = new ImbalanceNeigh(lmp);
+        nopt = imb->options(narg-iarg,arg+iarg+2);
+        imbalances[nimbalance++] = imb;
+      } else if (strcmp(arg[iarg+1],"var") == 0) {
+        varflag = 1;
+        imb = new ImbalanceVar(lmp);
+        nopt = imb->options(narg-iarg,arg+iarg+2);
+        imbalances[nimbalance++] = imb;
+      } else if (strcmp(arg[iarg+1],"store") == 0) {
+        imb = new ImbalanceStore(lmp);
+        nopt = imb->options(narg-iarg,arg+iarg+2);
+        imbalances[nimbalance++] = imb;
+      } else {
+        error->all(FLERR,"Unknown fix balance/all weight method: {}", arg[iarg+1]);
+      }
+      iarg += 1+nopt;
+    } else if (strcmp(arg[iarg],"verbose") == 0) {
+      verbose = true;
+    } else if (strcmp(arg[iarg],"global") == 0) {
+      if (iarg+2 >= narg) error->all(FLERR, "balance/all: histogram requires two arguments");
+      use_global_lb = true;
+      global_threshold = utils::numeric(FLERR,arg[iarg+1],false,lmp);
+      bw = utils::numeric(FLERR,arg[iarg+2],false,lmp);
+      iarg += 2;
+    } else if (strcmp(arg[iarg],"local") == 0) {
+      if (iarg+1 >= narg) error->all(FLERR, "balance/all: threshold requires one argument");
+      use_local_lb = true;
+      local_threshold = utils::numeric(FLERR,arg[iarg+1],false,lmp);
+      iarg++;
+    } else error->all(FLERR,"balance/all: unknown argument '{}'", arg[iarg]);
+  }
+
+  // check arguments
+  if (nevery < 1) error->all(FLERR,"balance/all: nevery > 0 required");
+  if (gridstyle == UNKNOWN_GRID) error->all(FLERR, "balance/all: grid style required");
+  if (use_global_lb) {
+    if (gridstyle != STAGGERED) error->all(FLERR, "balance/all: histogram requires staggered grid");
+    if (bw <= 0) error->all(FLERR, "balance/all: bw not positive");
+  }
+  if (! (use_local_lb || use_global_lb)) error->all(FLERR, "balance/all: at least local, global required");
+  if (use_local_lb && use_global_lb) {
+    if (local_threshold >= global_threshold) error->all(FLERR, "balance/all: local threshold < global threshold required");
+  }
+
+  // set comm style dependent on gridstyle ? see Input::comm_style()
+  // probably not since there is no running simulation in input (in contrast to here)
+  if (gridstyle == STAGGERED && comm->style != 2)
+    error->all(FLERR,"balance/all: comm_style staggered required for staggered grid");
+  if (gridstyle == TENSOR && comm->style != 0)
+    error->all(FLERR,"balance/all: comm_style brick required for tensor grid");
+
+  if (gridstyle == STAGGERED) {
+    all_local = new ALL::ALL<double, double>(ALL::STAGGERED, 3, 0);
+  } else if (gridstyle == TENSOR) {
+    if (tensorstyle == TENSOR_MAX) all_local = new ALL::ALL<double, double>(ALL::TENSOR_MAX, 3, 0);
+    else if (tensorstyle == TENSOR_CLASSIC) all_local = new ALL::ALL<double, double>(ALL::TENSOR, 3, 0);
+  }
+
+  if (use_global_lb) {
+    all_global = new ALL::ALL<double, double>(ALL::HISTOGRAM, 3, 0);
+    n_bins = std::vector<int>(3, -1);
+  }
+
+  all_last = nullptr;
+
+  global_freq = 1; // nevery;
+
+  irregular = new Irregular(lmp);
+
+  x_masters = MPI_COMM_NULL;
+  y_masters = MPI_COMM_NULL;
+  z_masters = MPI_COMM_NULL;
+
+  timer_lb = imbalance = maxloadperproc = -1;
+
+  force_reneighbor = 1;
+  lastbalance = -1;
+  next_reneighbor = -1;
+
+  reduce_outvec_flag = false;
+  for (int i = 0; i < 3; ++i) outvec_timer[i] = -1;
+}
+
+/**
+ *  Deconstructor. Free communicators and delete allocated memory.
+ */
+
+FixBalanceAll::~FixBalanceAll()
+{
+  all_last = nullptr;
+  if (all_local) delete all_local;
+  if (all_global) delete all_global;
+  delete irregular;
+
+  if (x_masters != MPI_COMM_NULL) MPI_Comm_free(&x_masters);
+  if (y_masters != MPI_COMM_NULL) MPI_Comm_free(&y_masters);
+  if (z_masters != MPI_COMM_NULL) MPI_Comm_free(&z_masters);
+
+  for (int i = 0; i < nimbalance; i++) delete imbalances[i];
+  delete[] imbalances;
+
+  // check nfix in case all fixes have already been deleted
+  if (fixstore && modify->nfix) modify->delete_fix(fixstore->id);
+  fixstore = nullptr;
+
+}
+
+/**
+ *  Post constructor. Setup weight storage.
+ */
+
+void FixBalanceAll::post_constructor()
+{
+  if (wtflag) weight_storage();
+}
+
+/**
+ *  For lammps. This fix is just called in pre_exchange.
+ *  @return mask
+ */
+
+int FixBalanceAll::setmask()
+{
+  int mask = 0;
+  mask |= PRE_EXCHANGE;
+  return mask;
+}
+
+/**
+ *  Initialise calculated variables and setup ALL objects.
+ *  Setup initial grid.
+ *  Write information to log.
+ */
+
+void FixBalanceAll::init()
+{
+  // called before every run
+
+  int counter = 0;
+  for (int i=0; i<modify->nfix; i++) {
+    if (strcmp(modify->fix[i]->style, "balance") == 0) counter++;
+    if (strcmp(modify->fix[i]->style, "balance/all") == 0) counter++;
+  }
+  if (counter > 1) error->all(FLERR, "More than one dynamic load balancing fix");
+
+  // get vectors as input for ALL
+
+  // use existing uniform grid
+  if (comm->layout == Comm::LAYOUT_TILED) error->all(FLERR, "balance/all: initialisation from Comm::LAYOUT_TILED not possible.");
+  if (comm->layout == Comm::LAYOUT_STAGGERED && gridstyle == TENSOR) error->all(FLERR, "balance/all: initialisation from Comm::STAGGERED not possible.");
+  if (gridstyle == STAGGERED && comm->style == 2 && (comm->staggered2spatial[0]!=2 || comm->staggered2spatial[1]!=1 || comm->staggered2spatial[2]!=0))
+    error->all(FLERR, "balance/all: comm_style staggered not zyx");
+  if (domain->dimension == 2 && comm->procgrid[2] != 1) error->all(FLERR,"balance/all: 2D-simulation not possible with {} processors in z-direction", comm->procgrid[2]);
+  procgrid_vec.assign(comm->procgrid, comm->procgrid+3);
+  myloc_vec.assign(comm->myloc, comm->myloc+3);
+
+  minimum_domain_size = {neighbor->skin, neighbor->skin, neighbor->skin};
+
+  // setup ALL
+
+  if (use_local_lb) {
+    all_local->setProcGridParams(myloc_vec, procgrid_vec);
+    all_local->setMinDomainSize(minimum_domain_size);
+    all_local->setCommunicator(world);
+    all_local->setProcTag(comm->me);
+    all_local->setup();
+  }
+
+  if (use_global_lb) {
+    all_global->setProcGridParams(myloc_vec, procgrid_vec);
+    all_global->setMinDomainSize(minimum_domain_size);
+    all_global->setCommunicator(world);
+    all_global->setProcTag(comm->me);
+    all_global->setup();
+  }
+
+  init_imbalance(1);
+
+  // create communicators for tensor
+  if (gridstyle == TENSOR) {
+    int color;
+    // There would be a way to create the communicator without communication, but split is easier to implement.
+
+    if (x_masters != MPI_COMM_NULL) MPI_Comm_free(&x_masters);
+    color = (myloc_vec[1] == 0 && myloc_vec[2] == 0) ? 0 : MPI_UNDEFINED;
+    MPI_Comm_split(world, color, myloc_vec[0], &x_masters);
+
+    if (y_masters != MPI_COMM_NULL) MPI_Comm_free(&y_masters);
+    color = (myloc_vec[0] == 0 && myloc_vec[2] == 0) ? 0 : MPI_UNDEFINED;
+    MPI_Comm_split(world, color, myloc_vec[1], &y_masters);
+
+    if (z_masters != MPI_COMM_NULL) MPI_Comm_free(&z_masters);
+    color = (myloc_vec[0] == 0 && myloc_vec[1] == 0) ? 0 : MPI_UNDEFINED;
+    MPI_Comm_split(world, color, myloc_vec[1], &z_masters);
+  }
+
+  next_reneighbor = (update->ntimestep/nevery)*nevery + nevery;
+
+  if (comm->me == 0) {
+    utils::logmesg(lmp, "ALL information ...\n");
+    utils::logmesg(lmp, "\tversion: 0.9.3\n");
+    if (gridstyle == STAGGERED) utils::logmesg(lmp, "\tgrid: staggered\n");
+    else if (gridstyle == TENSOR) utils::logmesg(lmp, "\tgrid: tensor\n");
+    utils::logmesg(lmp, "\tnumber of processors: {} x {} y {} z\n", procgrid_vec[0], procgrid_vec[1], procgrid_vec[2]);
+    if (use_global_lb) {
+      utils::logmesg(lmp, "\tglobal load balancing ...\n");
+      utils::logmesg(lmp, "\t\ttrigger threshold: {}\n", global_threshold);
+      utils::logmesg(lmp, "\t\tbin width: {}\n", bw);
+    }
+    if (use_local_lb) {
+      utils::logmesg(lmp, "\tlocal load balancing ...\n");
+      utils::logmesg(lmp, "\t\ttrigger threshold: {}\n", local_threshold);
+    }
+    if (verbose) utils::logmesg(lmp, "\tverbose output is used\n");
+  }
+}
+
+/**
+ *  Perform dynamic load balancing if required.
+ *  Calls corresponding local or global balancing function.
+ */
+
+void FixBalanceAll::pre_exchange()
+{
+  // return if not a rebalance timestep
+
+  if (update->ntimestep < next_reneighbor) return;
+
+  // next timestep to rebalance
+  next_reneighbor = (update->ntimestep/nevery)*nevery + nevery;
+
+  balance();
+}
+
+/**
+ *  Perform load balancing.
+ *  Calls corresponding local or global balancing function.
+ */
+
+void FixBalanceAll::balance()
+{
+  // do not allow rebalancing twice on same timestep
+  // even if you wanted to, it can mess up elapsed time
+
+  if (update->ntimestep == lastbalance) return;
+  lastbalance = update->ntimestep;
+
+  double timer_lb_start = platform::walltime();
+
+  set_weights();
+
+  work = get_work();
+
+  calc_imbalance();
+
+  // call load-balancing function if required
+  if (use_global_lb && imbalance > global_threshold)
+    balance_global();
+  else if (use_local_lb && imbalance > local_threshold)
+    balance_local();
+  else {
+    if (verbose && comm->me == 0) utils::logmesg(lmp, "balance/all: {} no balance required\n", imbalance);
+    all_last = nullptr;
+  }
+  unset_weights();
+
+  timer_lb = platform::walltime() - timer_lb_start;
+  reduce_outvec_flag = true;
+}
+
+/**
+ *  Perform staggered/tensor load balancing.
+ */
+
+void FixBalanceAll::balance_local()
+{
+  if (verbose && comm->me == 0) utils::logmesg(lmp, "balance/all: {} balance local\n", imbalance);
+
+  all_last = all_local;
+
+  // ensure atoms are in current box & update box via shrink-wrap
+  // no exchange() since doesn't matter if atoms are assigned to correct procs
+
+  domain->pbc();
+  domain->reset_box();
+
+  // The domain size is changed by adjusting the domain specific variables in comm.h
+  // local box is set with
+  // comm->{xsplit ysplit zsplit myloc procgrid} for tensor
+  // comm->mysplit                               for staggered
+
+  // rebalance with ALL
+  my_vertices = get_comm_vertices();
+  all_local->setVertices(my_vertices);
+  all_local->setWork(work);
+  all_local->balance();
+
+  set_comm_vertices(all_local->getVertices());
+  domain->set_local_box();
+
+  // not required since the minimum box size is also passed to all
+  // domain->subbox_too_small_check(neighbor->skin);
+
+  if (gridstyle == STAGGERED) irregular->migrate_atoms();
+  else if (irregular->migrate_check()) irregular->migrate_atoms();
+
+  modify->reset_grid();
+  if (force->pair) force->pair->reset_grid();
+  if (force->kspace) force->kspace->reset_grid();
+}
+
+/**
+ *  Perform histogram load balancing in z, y and x.
+ */
+
+void FixBalanceAll::balance_global()
+{
+  if (verbose && comm->me == 0) utils::logmesg(lmp, "balance/all: {} balance global\n", imbalance);
+
+  all_last = all_global;
+
+  // only for staggered
+  // histogram method
+
+  // insure atoms are in current box & update box via shrink-wrap
+  // no exchange() since doesn't matter if atoms are assigned to correct procs
+
+  domain->pbc();
+  domain->reset_box();
+
+  // processors may not have complex/simple particles yet, but get some during layer-balancing
+  // -> calculate global average
+  // only once since timers are evaluated
+
+  // atoms should be inside of the boundaries for the histogram calculation
+  irregular->migrate_atoms();
+
+  for (int dim_balance=2; dim_balance>=0; dim_balance--) {
+    // rebalance with ALL
+    my_vertices = get_comm_vertices();
+    all_global->setVertices(my_vertices);
+    all_global->setSysSize(get_sys_size_from_domain());
+
+    all_global->setWork(calc_histogram(dim_balance));
+    all_global->setMethodData(n_bins.data());
+
+    all_global->balance();
+    set_comm_vertices(all_global->getVertices());
+
+    domain->set_local_box();
+
+    irregular->migrate_atoms();
+  }
+
+  modify->reset_grid();
+  if (force->pair) force->pair->reset_grid();
+  if (force->kspace) force->kspace->reset_grid();
+
+}
+
+/**
+ *  Get the size of the simulation box from the domain class.
+ *  @return box size in box units with box origin in 0,0,0
+ */
+
+std::vector<double> FixBalanceAll::get_sys_size_from_domain()
+{
+  std::vector<double> sys_size(6);
+  sys_size.at(0) = 0;
+  sys_size.at(1) = domain->xprd;
+  sys_size.at(2) = 0;
+  sys_size.at(3) = domain->yprd;
+  sys_size.at(4) = 0;
+  sys_size.at(5) = domain->zprd;
+  return sys_size;
+}
+
+/**
+ *  Get size of this domain from class domain for setVertices of ALL.
+ *  @return size of this domain in ALL format
+ */
+
+std::vector<ALL::Point<double>> FixBalanceAll::get_comm_vertices()
+{
+  std::vector<ALL::Point<double>> vertices(2, ALL::Point<double>(3));
+  // comm stores the values in reduced coordinates in [0,1]
+  // -> multiply with box length per dimension
+  if (comm->layout == Comm::LAYOUT_STAGGERED) {
+    // tiled
+    vertices[0][0] = comm->mysplit[0][0] * domain->prd[0];
+    vertices[0][1] = comm->mysplit[1][0] * domain->prd[1];
+    vertices[0][2] = comm->mysplit[2][0] * domain->prd[2];
+    vertices[1][0] = comm->mysplit[0][1] * domain->prd[0];
+    vertices[1][1] = comm->mysplit[1][1] * domain->prd[1];
+    vertices[1][2] = comm->mysplit[2][1] * domain->prd[2];
+  } else {
+    // uniform
+    vertices[0][0] = comm->xsplit[comm->myloc[0]] * domain->prd[0];
+    vertices[0][1] = comm->ysplit[comm->myloc[1]] * domain->prd[1];
+    vertices[0][2] = comm->zsplit[comm->myloc[2]] * domain->prd[2];
+    vertices[1][0] = comm->xsplit[comm->myloc[0]+1] * domain->prd[0];
+    vertices[1][1] = comm->ysplit[comm->myloc[1]+1] * domain->prd[1];
+    vertices[1][2] = comm->zsplit[comm->myloc[2]+1] * domain->prd[2];
+  }
+
+  return vertices;
+}
+
+/**
+ *  Get load of this domain for imbalance calculation and setWork of
+ *  local ALL object.
+ *  @return work according to used definition
+ */
+
+double FixBalanceAll::get_work()
+{
+  double work = 0.0;
+
+  if (wtflag) {
+    weight = fixstore->vstore;
+    int nlocal = atom->nlocal;
+    for (int i = 0; i < nlocal; i++)
+      work += weight[i];
+
+  } else {
+    work = atom->nlocal;
+  }
+
+  return work;
+}
+
+/**
+ *  Set domain boundaries in class comm for tiled or brick layout.
+ *  @param[in] vertices returned by ALL object after load balancing step
+ *  @note updates layout, staggerednew, mysplit for staggered
+ *  @note updates xsplit, ysplit, zsplit for tensor
+ */
+
+void FixBalanceAll::set_comm_vertices(std::vector<ALL::Point<double>> vertices)
+{
+  if (gridstyle == STAGGERED) {
+    // set tiled values
+    comm->layout = Comm::LAYOUT_STAGGERED;
+    // comm stores the values in reduced coordinates in [0,1]
+    // -> divide by box length
+    comm->staggerednew = 1;
+
+    // just get the vertices
+    comm->mysplit[0][0] = vertices[0][0] / domain->prd[0];
+    comm->mysplit[1][0] = vertices[0][1] / domain->prd[1];
+    comm->mysplit[2][0] = vertices[0][2] / domain->prd[2];
+    comm->mysplit[0][1] = vertices[1][0] / domain->prd[0];
+    comm->mysplit[1][1] = vertices[1][1] / domain->prd[1];
+    comm->mysplit[2][1] = vertices[1][2] / domain->prd[2];
+
+    // prevention of floating point issues
+    for (int idim=0; idim<3; idim++) {
+      if (myloc_vec[idim] == 0) comm->mysplit[idim][0] = 0;
+      if (myloc_vec[idim] == procgrid_vec[idim]-1) comm->mysplit[idim][1] = 1;
+    }
+
+  } else {
+    // gridstyle == TENSOR
+
+    // rescale to [0:1]
+    vertices[1][0] /= domain->prd[0];
+    vertices[1][1] /= domain->prd[1];
+    vertices[1][2] /= domain->prd[2];
+
+    // xsplit ysplit zsplit contain all values
+    // split[0] is not changed, but it is zero anyway
+    // gather all upper boundaries on master
+    if (x_masters != MPI_COMM_NULL) MPI_Gather(&(vertices[1][0]), 1, MPI_DOUBLE, comm->xsplit+1, 1, MPI_DOUBLE, 0, x_masters);
+    if (y_masters != MPI_COMM_NULL) MPI_Gather(&(vertices[1][1]), 1, MPI_DOUBLE, comm->ysplit+1, 1, MPI_DOUBLE, 0, y_masters);
+    if (z_masters != MPI_COMM_NULL) MPI_Gather(&(vertices[1][2]), 1, MPI_DOUBLE, comm->zsplit+1, 1, MPI_DOUBLE, 0, z_masters);
+
+    // broadcast all boundaries from master
+    MPI_Bcast(comm->xsplit, comm->procgrid[0]+1, MPI_DOUBLE, 0, world);
+    MPI_Bcast(comm->ysplit, comm->procgrid[1]+1, MPI_DOUBLE, 0, world);
+    MPI_Bcast(comm->zsplit, comm->procgrid[2]+1, MPI_DOUBLE, 0, world);
+
+  }
+}
+
+/**
+ *  Calculate imbalance based on the current scalar work.
+ *  @note updates imbalance
+ */
+
+void FixBalanceAll::calc_imbalance()
+{
+  double max, avg;
+  MPI_Allreduce(&work, &avg, 1, MPI_DOUBLE, MPI_SUM, world);
+  avg /= comm->nprocs;
+  MPI_Allreduce(&work, &max, 1, MPI_DOUBLE, MPI_MAX, world);
+
+  maxloadperproc = max;
+
+  if ((max < 0 || avg < 0 || max < avg) && comm->me == 0) error->warning(FLERR, "cannot calculate imbalance with max={} avg={}", max, avg);
+
+  if (max == 0) {
+    imbalance = -1;
+  } else {
+    imbalance = max / avg;
+  }
+}
+
+/**
+ * invoke init() for each Imbalance class
+ * flag = 0 for call from Balance, 1 for call from FixBalance
+ */
+
+void FixBalanceAll::init_imbalance(int flag = 1)
+{
+  if (!wtflag) return;
+  for (int n = 0; n < nimbalance; n++) imbalances[n]->init(flag);
+}
+
+/**
+ *  allocate per-particle weight storage for histogram via FixStoreAtom
+ *  fix could already be allocated if fix balance is re-specified
+ */
+
+void FixBalanceAll::weight_storage()
+{
+  std::string cmd;
+  cmd = id;
+  cmd += "HISTOGRAM_WEIGHTS";
+  fixstore = dynamic_cast<FixStoreAtom *>(modify->get_fix_by_id(cmd));
+  if (!fixstore) fixstore = dynamic_cast<FixStoreAtom *>(modify->add_fix(cmd + " all STORE/ATOM 1 0 0 0"));
+
+  // do not carry weights with atoms during normal atom migration
+  fixstore->disable = 1;
+}
+
+/**
+  *  set weight for each particle
+  */
+
+void FixBalanceAll::set_weights()
+{
+  if (!wtflag) return;
+  weight = fixstore->vstore;
+
+  int nlocal = atom->nlocal;
+  for (int i = 0; i < nlocal; i++) weight[i] = 1.0;
+  for (int n = 0; n < nimbalance; n++) imbalances[n]->compute(weight);
+
+  // weights need to migrate with atoms
+  fixstore->disable = 0;
+}
+
+/**
+  *  prevent further migration of weights
+  */
+
+void FixBalanceAll::unset_weights()
+{
+  if (!wtflag) return;
+
+  // weights should not migrate with atoms
+  fixstore->disable = 1;
+}
+
+/**
+ *  Calculate histogram for setWork of histogram balancing.
+ *  @note updates n_bins
+ *  @param[in] dimension in which the histogram is calculated
+ *  @return histogram for setWork
+ */
+
+std::vector<double> FixBalanceAll::calc_histogram(int dimension)
+{
+  // calculate the histogram width in a way that lower and upper box boundary match with a bin boundary
+  int n_bins_global = std::ceil(domain->prd[dimension] / bw);
+  const double bin_width = domain->prd[dimension] / n_bins_global;
+
+  double lb = std::ceil(my_vertices[0][dimension] / bin_width) * bin_width;
+  double ub = std::ceil(my_vertices[1][dimension] / bin_width) * bin_width;
+
+  double overlap = 0; // bin -1 which is send to lower neighbour
+
+  n_bins.at(dimension) = (int) (std::round((ub -lb) / bin_width) + 1e-4);
+
+  std::vector<double> work_vec(n_bins.at(dimension), 0.0);
+
+  // compute histogram of work load
+  double ** x = atom->x;
+
+  // the work per atom is constant
+  // -> set work before iterating over atoms
+  double work_atom = 1.0;
+  double *weight = nullptr;
+  if (wtflag) weight = fixstore->vstore;
+
+  for (int i = 0; i < atom->nlocal; i++) {
+
+    // calculate bin of atom
+    const int idx = std::floor(((x[i][dimension] - domain->boxlo[dimension] - lb) / bin_width));
+
+    // use individual weight or previously defined work
+    if (wtflag) work_atom = weight[i];
+
+    // update corresponding bin
+    if (idx >= 0 && idx < n_bins.at(dimension)) {
+      work_vec.at(idx) += work_atom;
+    } else if (idx == -1) {
+      overlap += work_atom;
+    } else if (idx == n_bins.at(dimension) && fabs(x[i][dimension] - my_vertices[1][dimension]) < 1e-6) {
+      // floating point issue, just use the last bin
+      work_vec.at(n_bins.at(dimension) - 1) += work_atom;
+    } else {
+      error->one(FLERR, "balance/all: unexpected histogram bin {} for histogram of size {} x {} lb {} bin_width {} boxlo {} myvert_lo {} myvert_hi {}", idx, n_bins.at(dimension), x[i][dimension], lb, bin_width, domain->boxlo[dimension], my_vertices[0][dimension], my_vertices[1][dimension]);
+    }
+  }
+
+  // calculate ranks of neighbours
+  //myloc_vec.assign(comm->myloc, comm->myloc+3);
+  int rank_left = MPI_PROC_NULL;
+  int rank_right = MPI_PROC_NULL;
+  int loc_ngh[3];
+  loc_ngh[0] = myloc_vec[0];
+  loc_ngh[1] = myloc_vec[1];
+  loc_ngh[2] = myloc_vec[2];
+  // left neighbour
+  loc_ngh[dimension] -= 1;
+  if (loc_ngh[dimension] >= 0)
+    rank_left = comm->grid2proc[loc_ngh[0]][loc_ngh[1]][loc_ngh[2]];
+  // right neighbour
+  loc_ngh[dimension] += 2;
+  if (loc_ngh[dimension] < procgrid_vec[dimension])
+    rank_right = comm->grid2proc[loc_ngh[0]][loc_ngh[1]][loc_ngh[2]];
+
+  // exchange overlapping workload (histograms might overlap
+  // over the domain boundaries
+
+  MPI_Request sreq, rreq;
+  MPI_Status ssta, rsta;
+
+  double recv_work = 0;
+
+  MPI_Isend(&overlap, 1, MPI_DOUBLE, rank_left, 0, world, &sreq);
+  MPI_Irecv(&recv_work, 1, MPI_DOUBLE, rank_right, 0, world, &rreq);
+  MPI_Wait(&rreq, &rsta);
+  MPI_Wait(&sreq, &ssta);
+
+  work_vec.at(n_bins.at(dimension) - 1) += recv_work;
+
+  return work_vec;
+}
+
+/**
+ *  For lammps output only.
+ *  @param[in] i index of output vector
+ *  @return requested value
+ */
+
+double FixBalanceAll::compute_vector(int i)
+{
+  // TODO: remove communication and lb timing (doing more than required)
+  if (/*remove*/reduce_outvec_flag/*elsewhere*/) {
+    double reducebuffer_s, reducebuffer_r;
+    reducebuffer_s = /*remove!*/timer_lb/*elsewhere*/;
+
+    // calc min
+    MPI_Allreduce(&reducebuffer_s, &reducebuffer_r, 1, MPI_DOUBLE, MPI_MIN, world);
+    outvec_timer[0] = reducebuffer_r;
+
+    // calc avg
+    MPI_Allreduce(&reducebuffer_s, &reducebuffer_r, 1, MPI_DOUBLE, MPI_SUM, world);
+    outvec_timer[1] = reducebuffer_r / comm->nprocs;
+
+    // calc max
+    MPI_Allreduce(&reducebuffer_s, &reducebuffer_r, 1, MPI_DOUBLE, MPI_MAX, world);
+    outvec_timer[2] = reducebuffer_r;
+
+    reduce_outvec_flag = false;
+  }
+
+  if (i == 0) return maxloadperproc;
+  if (i == 1) return imbalance;
+  if (i <= 4) return outvec_timer[i-3];
+  return -1;
+}
+
+/**
+ *  For lammps stats only.
+ *  @return # of bytes of allocated memory
+ */
+
+double FixBalanceAll::memory_usage()
+{
+  double bytes = irregular->memory_usage();
+  return bytes;
+}
+
diff --git a/src/ALLPKG/fix_balance_all.h b/src/ALLPKG/fix_balance_all.h
new file mode 100644
index 0000000000..e7305ca832
--- /dev/null
+++ b/src/ALLPKG/fix_balance_all.h
@@ -0,0 +1,119 @@
+/* -*- c++ -*- ----------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+#ifdef FIX_CLASS
+// clang-format off
+FixStyle(balance/all,FixBalanceAll);
+// clang-format on
+#else
+
+#ifndef LMP_FIX_BALANCE_ALL_H
+#define LMP_FIX_BALANCE_ALL_H
+
+#include "fix.h"
+#include "ALL.hpp"
+#include "pointers.h"
+#include <mpi.h>
+
+namespace LAMMPS_NS {
+
+class FixBalanceAll : public Fix {
+ public:
+  FixBalanceAll(class LAMMPS *, int, char **);
+  ~FixBalanceAll() override;
+  int setmask() override;
+  void post_constructor() override;
+  void init() override;
+  void pre_exchange() override;
+  double compute_vector(int) override;
+  double memory_usage() override;
+
+ private:
+
+  bigint lastbalance;           // last timestep balancing was attempted
+
+  double maxloadperproc;        // max load on any processor
+
+  // user set variables
+
+  int nevery;                   // call load balancer after nevery steps
+  int gridstyle;                // STAGGERED, TENSOR, UNKNOWN_GRID
+  int wtflag;                   // use per atom weights 1, otherwise 0
+  int varflag;                  // 1 if weight style var(iable) is used
+  double bw;                    // bin width for histogram
+  double local_threshold;       // imbalance threshold for tensor and staggered
+  double global_threshold;      // imbalance threshold for histogram
+  bool use_bw_threshold;        // bin width threshold set
+  bool use_local_lb;            // all_local (staggered or tensor) required
+  bool use_global_lb;           // all_global (histogram) required
+  bool verbose;                 // write stats to log
+
+  // calculated variables
+
+  double work;                  // load of this rank
+  double imbalance;             // max work / avg work
+  double timer_lb;              // duration of load balancing step in seconds
+  MPI_Comm x_masters;           // for tensor to gather xsplit
+  MPI_Comm y_masters;           // for tensor to gather ysplit
+  MPI_Comm z_masters;           // for tensor to gather zsplit
+  bool reduce_outvec_flag;      // recaluclate out vector?
+  double outvec_timer[3]; // TODO: remove
+
+  // ALL objects
+
+  ALL::ALL<double, double> *all_local;   // staggered or tensor
+  ALL::ALL<double, double> *all_global;  // histogram
+  ALL::ALL<double, double> *all_last;    // pointer to last used object or nullptr
+
+  // ALL input
+
+  std::vector<int> n_bins;                      // number of bin of histogram
+  std::vector<int> myloc_vec;                   // position in staggered/tensor gird per dimension
+  std::vector<int> procgrid_vec;                // size of staggered/tensor grid per dimension
+  std::vector<double> minimum_domain_size;      // in box units [0, domain->prd]
+  std::vector<ALL::Point<double>> my_vertices;  // in box units [0, domain->prd]
+
+  // class pointers
+
+  class FixStoreAtom *fixstore;     // per-atom weights for histogram stored in FixStore
+  class Irregular *irregular;       // for atom migration after boudary update
+
+  int nimbalance;                   // number of user-specified weight styles
+  class Imbalance **imbalances;     // list of Imb classes, one per weight style
+  double *weight;                   // ptr to FixStore weight vector
+
+  // functions
+
+  std::vector<ALL::Point<double>> get_comm_vertices();
+  std::vector<double> calc_histogram(int);
+  std::vector<double> get_sys_size_from_domain();
+  double get_work();
+
+  void set_comm_vertices(std::vector<ALL::Point<double>>);
+
+  void balance();
+  void balance_local();
+  void balance_global();
+  void init_imbalance(int);
+  void calc_imbalance();
+  void set_weights();
+  void unset_weights();
+
+  void weight_storage();
+
+};
+
+}    // namespace LAMMPS_NS
+
+#endif
+#endif
diff --git a/src/Makefile b/src/Makefile
index c4eaa75a17..6697fa879f 100644
--- a/src/Makefile
+++ b/src/Makefile
@@ -52,6 +52,7 @@ PACKAGE = \
 	molecule \
 	kspace \
 	adios \
+	allpkg \
 	amoeba \
 	apip \
 	asphere \
@@ -238,6 +239,7 @@ PACKLIB = \
 	ml-quip \
 	rheo \
 	scafacos \
+	allpkg \
 	machdyn \
 	vtk \
 	electrode
@@ -248,6 +250,7 @@ PACKINT = atc awpmd colvars electrode gpu kokkos lepton ml-pod poems
 
 PACKEXT = \
 	adios \
+	allpkg \
 	apip \
 	h5md \
 	kim \
diff --git a/src/comm.cpp b/src/comm.cpp
index 340308c7b3..0d647e9ed3 100644
--- a/src/comm.cpp
+++ b/src/comm.cpp
@@ -78,8 +78,11 @@ Comm::Comm(LAMMPS *lmp) : Pointers(lmp)
   bufextra_max = bufextra;
 
   grid2proc = nullptr;
+  staggered_grid2proc = nullptr;
+  staggered_proc2grid = nullptr;
   xsplit = ysplit = zsplit = nullptr;
   rcbnew = 0;
+  staggerednew = 0;
   multi_reduce = 0;
 
   // use of OpenMP threads
@@ -109,6 +112,7 @@ Comm::Comm(LAMMPS *lmp) : Pointers(lmp)
   if (me == 0)
     utils::logmesg(lmp,"  using {} OpenMP thread(s) per MPI task\n",nthreads);
 #endif
+  mysplit[0][0] = mysplit[0][1] = mysplit[1][0] = mysplit[1][1] = mysplit[2][0] = mysplit[2][1] = 0;
 
 }
 
@@ -117,6 +121,8 @@ Comm::Comm(LAMMPS *lmp) : Pointers(lmp)
 Comm::~Comm()
 {
   memory->destroy(grid2proc);
+  memory->destroy(staggered_grid2proc);
+  memory->destroy(staggered_proc2grid);
   memory->destroy(xsplit);
   memory->destroy(ysplit);
   memory->destroy(zsplit);
diff --git a/src/comm.h b/src/comm.h
index 13e44eda57..7d2549d1ad 100644
--- a/src/comm.h
+++ b/src/comm.h
@@ -20,14 +20,16 @@ namespace LAMMPS_NS {
 
 class Comm : protected Pointers {
  public:
-  enum { BRICK, TILED };
+  enum { BRICK, TILED, STAGGERED };
   int style;    // BRICK = 6-way stencil communication
                 // TILED = irregular tiling communication
+                // STAGGERED = staggered communication
 
-  enum { LAYOUT_UNIFORM, LAYOUT_NONUNIFORM, LAYOUT_TILED };
+  enum { LAYOUT_UNIFORM, LAYOUT_NONUNIFORM, LAYOUT_TILED, LAYOUT_STAGGERED };
   int layout;    // LAYOUT_UNIFORM = equal-sized bricks
                  // LAYOUT_NONUNIFORM = logical bricks, but diff sizes via LB
                  // LAYOUT_TILED = general tiling, due to RCB LB
+                 // LAYOUT_STAGGERED = staggered mesh due to LB
   enum { SINGLE, MULTI, MULTIOLD };
   int mode;    // SINGLE = single cutoff
                // MULTI = multi-collection cutoff
@@ -65,6 +67,17 @@ class Comm : protected Pointers {
   double rcbcutfrac;       // fractional RCB cut by this proc
   int rcbcutdim;           // dimension of RCB cut
 
+  // public settings specific to layout = STAGGERED
+
+  int *** staggered_grid2proc;      // which proc owns layer,row,cell in staggered grid
+  int ** staggered_proc2grid;       // which location (layer,row,cell) is owned by proc in staggered grid
+  int staggerednew;                 // 1 if just reset by rebalance, else 0
+  int staggered_procgrid[3];        // layers, rows, cells
+  int staggered_myloc[3];           // layers, rows, cells
+  int n_layers, n_rows, n_cells;    // number of layers/rows/cells
+  int staggered2spatial[3];         // layer/row/cell to x/y/z
+  int spatial2staggered[3];         // x/y/z to layer/row/cell
+
   // methods
 
   Comm(class LAMMPS *);
diff --git a/src/comm_staggered.cpp b/src/comm_staggered.cpp
new file mode 100644
index 0000000000..5418f0e3e8
--- /dev/null
+++ b/src/comm_staggered.cpp
@@ -0,0 +1,1215 @@
+// clang-format off
+/* ----------------------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+#include "comm_staggered.h"
+
+#include "atom.h"
+#include "atom_vec.h"
+#include "bond.h"
+#include "compute.h"
+#include "domain.h"
+#include "dump.h"
+#include "error.h"
+#include "fix.h"
+#include "memory.h"
+#include "neighbor.h"
+#include "pair.h"
+
+#include <cmath>
+#include <cstring>
+
+using namespace LAMMPS_NS;
+
+static constexpr double BUFFACTOR = 1.5;
+static constexpr int BUFMIN = 1024;
+static constexpr double EPSILON = 1.0e-6;
+static constexpr int DELTA_PROCS = 16;
+
+
+/* ---------------------------------------------------------------------- */
+//IMPORTANT: we *MUST* pass "*oldcomm" to the Comm initializer here, as
+//           the code below *requires* that the (implicit) copy constructor
+//           for Comm is run and thus creating a shallow copy of "oldcomm".
+//           The call to Comm::copy_arrays() then converts the shallow copy
+//           into a deep copy of the class with the new layout.
+//           @todo search 'comm->layout' and adapt foreign functions for
+//                  LAYOUT_STAGGERED
+
+CommStaggered::CommStaggered(LAMMPS *lmp, Comm *oldcomm, char *arg) : CommTiled(lmp, oldcomm)
+{
+  if (oldcomm->layout == Comm::LAYOUT_TILED)
+    error->all(FLERR,"Cannot change to comm_style staggered from tiled layout");
+  if (oldcomm->layout == Comm::LAYOUT_STAGGERED)
+    error->all(FLERR,"Conversion from staggered layout to staggered layout is not allowed");
+
+  style = Comm::STAGGERED;
+  if (strlen(arg) != 3) error->all(FLERR, "expected 3 chars instead of {}", strlen(arg));
+  for (int i = 0; i < 3; i++) {
+    if (arg[i] == 'x') staggered2spatial[i] = 0;
+    else if (arg[i] == 'y') staggered2spatial[i] = 1;
+    else if (arg[i] == 'z') staggered2spatial[i] = 2;
+    else error->all(FLERR, "expected x,y or z instead of {} in staggered config", arg[i]);
+    spatial2staggered[staggered2spatial[i]] = i;
+  }
+
+  init_buffers_staggered();
+}
+
+/**
+  * Free allocated memory specific to staggered.
+  */
+
+CommStaggered::~CommStaggered()
+{
+  if (layer_splits) memory->destroy(layer_splits);
+  if (row_splits) memory->destroy(row_splits);
+  if (cell_splits) memory->destroy(cell_splits);
+}
+
+/**
+  * initialise comm buffers and other data structs local to CommStaggered but not to CommTiled
+  */
+
+void CommStaggered::init_buffers_staggered()
+{
+  // allocate memory and store constant quantities
+  for (int i = 0; i < 3; i++) {
+    staggered_procgrid[spatial2staggered[i]] = procgrid[i];
+    staggered_myloc[spatial2staggered[i]] = myloc[i];
+  }
+  n_layers = staggered_procgrid[0];
+  n_rows = staggered_procgrid[1];
+  n_cells = staggered_procgrid[2];
+
+  memory->create(layer_splits, n_layers+1, "comm:layer_splits");
+  memory->create(row_splits, n_layers, n_rows+1, "comm:row_splits");
+  memory->create(cell_splits, n_layers, n_rows, n_cells+1, "comm:cell_splits");
+  memory->create(staggered_grid2proc, n_layers, n_rows, n_cells, "comm:staggered_grid2proc");
+  memory->create(staggered_proc2grid, nprocs, 3, "comm:staggered_proc2grid");
+
+  int tmploc[3];
+  for (tmploc[0] = 0; tmploc[0] < n_layers; tmploc[0]++) {
+    for (tmploc[1] = 0; tmploc[1] < n_rows; tmploc[1]++) {
+      for (tmploc[2] = 0; tmploc[2] < n_cells; tmploc[2]++) {
+        staggered_grid2proc[tmploc[0]][tmploc[1]][tmploc[2]] = grid2proc[tmploc[spatial2staggered[0]]]
+                                                   [tmploc[spatial2staggered[1]]]
+                                                   [tmploc[spatial2staggered[2]]];
+      }
+    }
+  }
+  int gatherbuffer[nprocs*3];
+  gatherbuffer[me*3+0] = staggered_myloc[0];
+  gatherbuffer[me*3+1] = staggered_myloc[1];
+  gatherbuffer[me*3+2] = staggered_myloc[2];
+  MPI_Allgather(MPI_IN_PLACE,3,MPI_INT,gatherbuffer,3,MPI_INT,world);
+  for (int i=0; i < nprocs; i++) {
+    staggered_proc2grid[i][0] = gatherbuffer[i*3+0];
+    staggered_proc2grid[i][1] = gatherbuffer[i*3+1];
+    staggered_proc2grid[i][2] = gatherbuffer[i*3+2];
+  }
+}
+
+/**
+  * setup spatial-decomposition communication patterns
+  * function of neighbor cutoff(s) & cutghostuser & current box size and tiling
+  */
+
+void CommStaggered::setup()
+{
+  int i,j,n;
+
+  // domain properties used in setup method and methods it calls
+
+  dimension = domain->dimension;
+  int *periodicity = domain->periodicity;
+  int ntypes = atom->ntypes;
+
+  if (triclinic == 0) {
+    prd = domain->prd;
+    boxlo = domain->boxlo;
+    boxhi = domain->boxhi;
+    sublo = domain->sublo;
+    subhi = domain->subhi;
+  } else {
+    prd = domain->prd_lamda;
+    boxlo = domain->boxlo_lamda;
+    boxhi = domain->boxhi_lamda;
+    sublo = domain->sublo_lamda;
+    subhi = domain->subhi_lamda;
+  }
+
+  // set function pointers
+
+  if (layout == Comm::LAYOUT_STAGGERED) {
+    box_drop = &CommStaggered::box_drop_staggered;
+    box_other = &CommStaggered::box_other_staggered;
+    box_touch = &CommStaggered::box_touch_staggered;
+    point_drop = &CommStaggered::point_drop_staggered;
+  } else {
+    // set brick for this class
+    box_drop = &CommStaggered::box_drop_brick;
+    box_other = &CommStaggered::box_other_brick;
+    box_touch = &CommStaggered::box_touch_brick;
+    point_drop = &CommStaggered::point_drop_brick;
+    // set brick for parent class
+    CommTiled::box_drop = &CommStaggered::box_drop_brick;
+    CommTiled::box_other = &CommStaggered::box_other_brick;
+    CommTiled::box_touch = &CommStaggered::box_touch_brick;
+    CommTiled::point_drop = &CommStaggered::point_drop_brick;
+  }
+
+  // if RCB decomp exists and just changed, gather needed global RCB info
+
+  if (layout == Comm::LAYOUT_STAGGERED) coord2proc_setup();
+
+  // set cutoff for comm forward and comm reverse
+  // check that cutoff < any periodic box length
+
+  if (mode == Comm::MULTI) {
+    double **cutcollectionsq = neighbor->cutcollectionsq;
+
+    // build collection array for atom exchange
+    neighbor->build_collection(0);
+
+    // If using multi/reduce, communicate particles a distance equal
+    // to the max cutoff with equally sized or smaller collections
+    // If not, communicate the maximum cutoff of the entire collection
+    for (i = 0; i < ncollections; i++) {
+      if (cutusermulti) {
+        cutghostmulti[i][0] = cutusermulti[i];
+        cutghostmulti[i][1] = cutusermulti[i];
+        cutghostmulti[i][2] = cutusermulti[i];
+      } else {
+        cutghostmulti[i][0] = 0.0;
+        cutghostmulti[i][1] = 0.0;
+        cutghostmulti[i][2] = 0.0;
+      }
+
+      for (j = 0; j < ncollections; j++){
+        if (multi_reduce && (cutcollectionsq[j][j] > cutcollectionsq[i][i])) continue;
+        cutghostmulti[i][0] = MAX(cutghostmulti[i][0],sqrt(cutcollectionsq[i][j]));
+        cutghostmulti[i][1] = MAX(cutghostmulti[i][1],sqrt(cutcollectionsq[i][j]));
+        cutghostmulti[i][2] = MAX(cutghostmulti[i][2],sqrt(cutcollectionsq[i][j]));
+      }
+    }
+  }
+
+  if (mode == Comm::MULTIOLD) {
+    double *cuttype = neighbor->cuttype;
+    for (i = 1; i <= ntypes; i++) {
+      double tmp = 0.0;
+      if (cutusermultiold) tmp = cutusermultiold[i];
+      cutghostmultiold[i][0] = MAX(tmp,cuttype[i]);
+      cutghostmultiold[i][1] = MAX(tmp,cuttype[i]);
+      cutghostmultiold[i][2] = MAX(tmp,cuttype[i]);
+    }
+  }
+
+  double cut = get_comm_cutoff();
+  if ((cut == 0.0) && (me == 0))
+    error->warning(FLERR,"Communication cutoff is 0.0. No ghost atoms "
+                   "will be generated. Atoms may get lost.");
+
+  if (triclinic == 0) cutghost[0] = cutghost[1] = cutghost[2] = cut;
+  else {
+    double *h_inv = domain->h_inv;
+    double length0,length1,length2;
+    length0 = sqrt(h_inv[0]*h_inv[0] + h_inv[5]*h_inv[5] + h_inv[4]*h_inv[4]);
+    cutghost[0] = cut * length0;
+    length1 = sqrt(h_inv[1]*h_inv[1] + h_inv[3]*h_inv[3]);
+    cutghost[1] = cut * length1;
+    length2 = h_inv[2];
+    cutghost[2] = cut * length2;
+    if (mode == Comm::MULTI) {
+      for (i = 0; i < ncollections; i++) {
+        cutghostmulti[i][0] *= length0;
+        cutghostmulti[i][1] *= length1;
+        cutghostmulti[i][2] *= length2;
+      }
+    }
+
+    if (mode == Comm::MULTIOLD) {
+      for (i = 1; i <= ntypes; i++) {
+        cutghostmultiold[i][0] *= length0;
+        cutghostmultiold[i][1] *= length1;
+        cutghostmultiold[i][2] *= length2;
+      }
+    }
+  }
+
+  if ((periodicity[0] && cutghost[0] > prd[0]) ||
+      (periodicity[1] && cutghost[1] > prd[1]) ||
+      (dimension == 3 && periodicity[2] && cutghost[2] > prd[2]))
+    error->all(FLERR,"Communication cutoff for comm_style tiled "
+               "cannot exceed periodic box length");
+
+  // if cut = 0.0, set to epsilon to induce nearest neighbor comm
+  // this is b/c sendproc is used below to infer touching exchange procs
+  // exchange procs will be empty (leading to lost atoms) if sendproc = 0
+  // will reset sendproc/etc to 0 after exchange is setup, down below
+
+  int cutzero = 0;
+  if (cut == 0.0) {
+    cutzero = 1;
+    cut = MIN(prd[0],prd[1]);
+    if (dimension == 3) cut = MIN(cut,prd[2]);
+    cut *= EPSILON*EPSILON;
+    cutghost[0] = cutghost[1] = cutghost[2] = cut;
+  }
+
+  // setup forward/reverse communication
+  // loop over 6 swap directions
+  // determine which procs I will send to and receive from in each swap
+  // done by intersecting ghost box with all proc sub-boxes it overlaps
+  // sets nsendproc, nrecvproc, sendproc, recvproc
+  // sets sendother, recvother, sendself, pbc_flag, pbc, sendbox
+  // resets nprocmax
+
+  int noverlap1,indexme;
+  double lo1[3],hi1[3],lo2[3],hi2[3];
+  int one,two;
+
+  int iswap = 0;
+  for (int idim = 0; idim < dimension; idim++) {
+    for (int idir = 0; idir < 2; idir++) {
+
+      // one = first ghost box in same periodic image
+      // two = second ghost box wrapped across periodic boundary
+      // either may not exist
+
+      one = 1;
+      lo1[0] = sublo[0]; lo1[1] = sublo[1]; lo1[2] = sublo[2];
+      hi1[0] = subhi[0]; hi1[1] = subhi[1]; hi1[2] = subhi[2];
+      if (idir == 0) {
+        lo1[idim] = sublo[idim] - cutghost[idim];
+        hi1[idim] = sublo[idim];
+      } else {
+        lo1[idim] = subhi[idim];
+        hi1[idim] = subhi[idim] + cutghost[idim];
+      }
+
+      two = 0;
+      if (idir == 0 && periodicity[idim] && lo1[idim] < boxlo[idim]) two = 1;
+      if (idir == 1 && periodicity[idim] && hi1[idim] > boxhi[idim]) two = 1;
+
+      if (two) {
+        lo2[0] = sublo[0]; lo2[1] = sublo[1]; lo2[2] = sublo[2];
+        hi2[0] = subhi[0]; hi2[1] = subhi[1]; hi2[2] = subhi[2];
+        if (idir == 0) {
+          lo2[idim] = lo1[idim] + prd[idim];
+          hi2[idim] = boxhi[idim];
+          if (sublo[idim] == boxlo[idim]) one = 0;
+        } else {
+          lo2[idim] = boxlo[idim];
+          hi2[idim] = hi1[idim] - prd[idim];
+          if (subhi[idim] == boxhi[idim]) one = 0;
+        }
+      }
+
+      if (one) {
+        if (idir == 0) lo1[idim] = MAX(lo1[idim],boxlo[idim]);
+        else hi1[idim] = MIN(hi1[idim],boxhi[idim]);
+        if (lo1[idim] == hi1[idim]) one = 0;
+      }
+      if (one && idir == 0 && layout == Comm::LAYOUT_STAGGERED && staggered_myloc[spatial2staggered[idim]] == 0) error->one(FLERR, "one set for communication in direction 0, but there is no processor");
+      if (one && idir == 1 && layout == Comm::LAYOUT_STAGGERED && staggered_myloc[spatial2staggered[idim]] == staggered_procgrid[spatial2staggered[idim]] -1) error->one(FLERR, "one set for communication in direction 1, but there is no processor");
+
+      // noverlap = # of overlaps of box1/2 with procs via box_drop()
+      // overlap = list of overlapping procs
+      // if overlap with self, indexme = index of me in list
+
+      indexme = -1;
+      noverlap = 0;
+
+      if (one) (this->*box_drop)(idim,lo1,hi1,indexme);
+      noverlap1 = noverlap;
+      if (two) (this->*box_drop)(idim,lo2,hi2,indexme);
+
+      // if self is in overlap list, move it to end of list
+
+      if (indexme >= 0) {
+        int tmp = overlap[noverlap-1];
+        overlap[noverlap-1] = overlap[indexme];
+        overlap[indexme] = tmp;
+      }
+
+      // reallocate 2nd dimensions of all send/recv arrays, based on noverlap
+      // # of sends of this swap = # of recvs of iswap +/- 1
+
+      if (noverlap > nprocmax[iswap]) {
+        int oldmax = nprocmax[iswap];
+        while (nprocmax[iswap] < noverlap) nprocmax[iswap] += DELTA_PROCS;
+        grow_swap_send(iswap,nprocmax[iswap],oldmax);
+        if (idir == 0) grow_swap_recv(iswap+1,nprocmax[iswap]);
+        else grow_swap_recv(iswap-1,nprocmax[iswap]);
+      }
+
+      // overlap how has list of noverlap procs
+      // includes PBC effects
+
+      if (noverlap && overlap[noverlap-1] == me) sendself[iswap] = 1;
+      else sendself[iswap] = 0;
+      if (noverlap && noverlap-sendself[iswap]) sendother[iswap] = 1;
+      else sendother[iswap] = 0;
+
+      nsendproc[iswap] = noverlap;
+      for (i = 0; i < noverlap; i++) sendproc[iswap][i] = overlap[i];
+
+      if (idir == 0) {
+        recvother[iswap+1] = sendother[iswap];
+        nrecvproc[iswap+1] = noverlap;
+        for (i = 0; i < noverlap; i++) recvproc[iswap+1][i] = overlap[i];
+      } else {
+        recvother[iswap-1] = sendother[iswap];
+        nrecvproc[iswap-1] = noverlap;
+        for (i = 0; i < noverlap; i++) recvproc[iswap-1][i] = overlap[i];
+      }
+
+      // compute sendbox for each of my sends
+      // obox = intersection of ghostbox with other proc's sub-domain
+      // sbox = what I need to send to other proc
+      //      = sublo to MIN(sublo+cut,subhi) in idim, for idir = 0
+      //      = MIN(subhi-cut,sublo) to subhi in idim, for idir = 1
+      //      = obox in other 2 dims
+      // if sbox touches other proc's sub-box boundaries in lower dims,
+      //   extend sbox in those lower dims to include ghost atoms
+      // single mode and multi mode
+
+      double oboxlo[3],oboxhi[3],sbox[6],sbox_multi[6],sbox_multiold[6];
+
+      if (mode == Comm::SINGLE) {
+        for (i = 0; i < noverlap; i++) {
+          pbc_flag[iswap][i] = 0;
+          pbc[iswap][i][0] = pbc[iswap][i][1] = pbc[iswap][i][2] =
+            pbc[iswap][i][3] = pbc[iswap][i][4] = pbc[iswap][i][5] = 0;
+
+          (this->*box_other)(idim,idir,overlap[i],oboxlo,oboxhi);
+
+          if (i < noverlap1) {
+            sbox[0] = MAX(oboxlo[0],lo1[0]);
+            sbox[1] = MAX(oboxlo[1],lo1[1]);
+            sbox[2] = MAX(oboxlo[2],lo1[2]);
+            sbox[3] = MIN(oboxhi[0],hi1[0]);
+            sbox[4] = MIN(oboxhi[1],hi1[1]);
+            sbox[5] = MIN(oboxhi[2],hi1[2]);
+          } else {
+            pbc_flag[iswap][i] = 1;
+            if (idir == 0) pbc[iswap][i][idim] = 1;
+            else pbc[iswap][i][idim] = -1;
+            if (triclinic) {
+              if (idim == 1) pbc[iswap][i][5] = pbc[iswap][i][idim];
+              if (idim == 2) pbc[iswap][i][4] = pbc[iswap][i][3] = pbc[iswap][i][idim];
+            }
+            sbox[0] = MAX(oboxlo[0],lo2[0]);
+            sbox[1] = MAX(oboxlo[1],lo2[1]);
+            sbox[2] = MAX(oboxlo[2],lo2[2]);
+            sbox[3] = MIN(oboxhi[0],hi2[0]);
+            sbox[4] = MIN(oboxhi[1],hi2[1]);
+            sbox[5] = MIN(oboxhi[2],hi2[2]);
+          }
+
+          if (idir == 0) {
+            sbox[idim] = sublo[idim];
+            if (i < noverlap1)
+              sbox[3+idim] = MIN(sbox[3+idim]+cutghost[idim],subhi[idim]);
+            else
+              sbox[3+idim] = MIN(sbox[3+idim]-prd[idim]+cutghost[idim],subhi[idim]);
+          } else {
+            if (i < noverlap1) sbox[idim] = MAX(sbox[idim]-cutghost[idim],sublo[idim]);
+            else sbox[idim] = MAX(sbox[idim]+prd[idim]-cutghost[idim],sublo[idim]);
+            sbox[3+idim] = subhi[idim];
+          }
+
+          if (idim >= 1) {
+            if (sbox[0] == oboxlo[0]) sbox[0] -= cutghost[0];
+            if (sbox[3] == oboxhi[0]) sbox[3] += cutghost[0];
+          }
+          if (idim == 2) {
+            if (sbox[1] == oboxlo[1]) sbox[1] -= cutghost[1];
+            if (sbox[4] == oboxhi[1]) sbox[4] += cutghost[1];
+          }
+
+          memcpy(sendbox[iswap][i],sbox,6*sizeof(double));
+        }
+      }
+
+      if (mode == Comm::MULTI) {
+        for (i = 0; i < noverlap; i++) {
+          pbc_flag[iswap][i] = 0;
+          pbc[iswap][i][0] = pbc[iswap][i][1] = pbc[iswap][i][2] =
+            pbc[iswap][i][3] = pbc[iswap][i][4] = pbc[iswap][i][5] = 0;
+
+          (this->*box_other)(idim,idir,overlap[i],oboxlo,oboxhi);
+
+          if (i < noverlap1) {
+            sbox[0] = MAX(oboxlo[0],lo1[0]);
+            sbox[1] = MAX(oboxlo[1],lo1[1]);
+            sbox[2] = MAX(oboxlo[2],lo1[2]);
+            sbox[3] = MIN(oboxhi[0],hi1[0]);
+            sbox[4] = MIN(oboxhi[1],hi1[1]);
+            sbox[5] = MIN(oboxhi[2],hi1[2]);
+          } else {
+            pbc_flag[iswap][i] = 1;
+            if (idir == 0) pbc[iswap][i][idim] = 1;
+            else pbc[iswap][i][idim] = -1;
+            if (triclinic) {
+              if (idim == 1) pbc[iswap][i][5] = pbc[iswap][i][idim];
+              if (idim == 2) pbc[iswap][i][4] = pbc[iswap][i][3] = pbc[iswap][i][idim];
+            }
+            sbox[0] = MAX(oboxlo[0],lo2[0]);
+            sbox[1] = MAX(oboxlo[1],lo2[1]);
+            sbox[2] = MAX(oboxlo[2],lo2[2]);
+            sbox[3] = MIN(oboxhi[0],hi2[0]);
+            sbox[4] = MIN(oboxhi[1],hi2[1]);
+            sbox[5] = MIN(oboxhi[2],hi2[2]);
+          }
+
+          for (int icollection = 0; icollection < ncollections; icollection++) {
+            sbox_multi[0] = sbox[0];
+            sbox_multi[1] = sbox[1];
+            sbox_multi[2] = sbox[2];
+            sbox_multi[3] = sbox[3];
+            sbox_multi[4] = sbox[4];
+            sbox_multi[5] = sbox[5];
+            if (idir == 0) {
+              sbox_multi[idim] = sublo[idim];
+              if (i < noverlap1)
+                sbox_multi[3+idim] =
+                  MIN(sbox_multi[3+idim]+cutghostmulti[icollection][idim],subhi[idim]);
+              else
+                sbox_multi[3+idim] =
+                  MIN(sbox_multi[3+idim]-prd[idim]+cutghostmulti[icollection][idim],subhi[idim]);
+            } else {
+              if (i < noverlap1)
+                sbox_multi[idim] =
+                  MAX(sbox_multi[idim]-cutghostmulti[icollection][idim],sublo[idim]);
+              else
+                sbox_multi[idim] =
+                  MAX(sbox_multi[idim]+prd[idim]-cutghostmulti[icollection][idim],sublo[idim]);
+              sbox_multi[3+idim] = subhi[idim];
+            }
+
+            if (idim >= 1) {
+              if (sbox_multi[0] == oboxlo[0])
+                sbox_multi[0] -= cutghostmulti[icollection][idim];
+              if (sbox_multi[3] == oboxhi[0])
+                sbox_multi[3] += cutghostmulti[icollection][idim];
+            }
+            if (idim == 2) {
+              if (sbox_multi[1] == oboxlo[1])
+                sbox_multi[1] -= cutghostmulti[icollection][idim];
+              if (sbox_multi[4] == oboxhi[1])
+                sbox_multi[4] += cutghostmulti[icollection][idim];
+            }
+
+            memcpy(sendbox_multi[iswap][i][icollection],sbox_multi,6*sizeof(double));
+          }
+        }
+      }
+
+      if (mode == Comm::MULTIOLD) {
+        for (i = 0; i < noverlap; i++) {
+          pbc_flag[iswap][i] = 0;
+          pbc[iswap][i][0] = pbc[iswap][i][1] = pbc[iswap][i][2] =
+            pbc[iswap][i][3] = pbc[iswap][i][4] = pbc[iswap][i][5] = 0;
+
+          (this->*box_other)(idim,idir,overlap[i],oboxlo,oboxhi);
+
+          if (i < noverlap1) {
+            sbox[0] = MAX(oboxlo[0],lo1[0]);
+            sbox[1] = MAX(oboxlo[1],lo1[1]);
+            sbox[2] = MAX(oboxlo[2],lo1[2]);
+            sbox[3] = MIN(oboxhi[0],hi1[0]);
+            sbox[4] = MIN(oboxhi[1],hi1[1]);
+            sbox[5] = MIN(oboxhi[2],hi1[2]);
+          } else {
+            pbc_flag[iswap][i] = 1;
+            if (idir == 0) pbc[iswap][i][idim] = 1;
+            else pbc[iswap][i][idim] = -1;
+            if (triclinic) {
+              if (idim == 1) pbc[iswap][i][5] = pbc[iswap][i][idim];
+              if (idim == 2) pbc[iswap][i][4] = pbc[iswap][i][3] = pbc[iswap][i][idim];
+            }
+            sbox[0] = MAX(oboxlo[0],lo2[0]);
+            sbox[1] = MAX(oboxlo[1],lo2[1]);
+            sbox[2] = MAX(oboxlo[2],lo2[2]);
+            sbox[3] = MIN(oboxhi[0],hi2[0]);
+            sbox[4] = MIN(oboxhi[1],hi2[1]);
+            sbox[5] = MIN(oboxhi[2],hi2[2]);
+          }
+
+          for (int itype = 1; itype <= atom->ntypes; itype++) {
+            sbox_multiold[0] = sbox[0];
+            sbox_multiold[1] = sbox[1];
+            sbox_multiold[2] = sbox[2];
+            sbox_multiold[3] = sbox[3];
+            sbox_multiold[4] = sbox[4];
+            sbox_multiold[5] = sbox[5];
+            if (idir == 0) {
+              sbox_multiold[idim] = sublo[idim];
+              if (i < noverlap1)
+                sbox_multiold[3+idim] =
+                  MIN(sbox_multiold[3+idim]+cutghostmultiold[itype][idim],subhi[idim]);
+              else
+                sbox_multiold[3+idim] =
+                  MIN(sbox_multiold[3+idim]-prd[idim]+cutghostmultiold[itype][idim],subhi[idim]);
+            } else {
+              if (i < noverlap1)
+                sbox_multiold[idim] =
+                  MAX(sbox_multiold[idim]-cutghostmultiold[itype][idim],sublo[idim]);
+              else
+                sbox_multiold[idim] =
+                  MAX(sbox_multiold[idim]+prd[idim]-cutghostmultiold[itype][idim],sublo[idim]);
+              sbox_multiold[3+idim] = subhi[idim];
+            }
+
+            if (idim >= 1) {
+              if (sbox_multiold[0] == oboxlo[0])
+                sbox_multiold[0] -= cutghostmultiold[itype][idim];
+              if (sbox_multiold[3] == oboxhi[0])
+                sbox_multiold[3] += cutghostmultiold[itype][idim];
+            }
+            if (idim == 2) {
+              if (sbox_multiold[1] == oboxlo[1])
+                sbox_multiold[1] -= cutghostmultiold[itype][idim];
+              if (sbox_multiold[4] == oboxhi[1])
+                sbox_multiold[4] += cutghostmultiold[itype][idim];
+            }
+
+            memcpy(sendbox_multiold[iswap][i][itype],sbox_multiold,6*sizeof(double));
+          }
+        }
+      }
+
+      iswap++;
+    }
+  }
+
+
+  // setup exchange communication = subset of forward/reverse comm procs
+  // loop over dimensions
+  // determine which procs I will exchange with in each dimension
+  // subset of procs that touch my proc in forward/reverse comm
+  // sets nexchproc & exchproc, resets nexchprocmax
+
+  int proc;
+
+  for (int idim = 0; idim < dimension; idim++) {
+
+    // overlap = list of procs that touch my sub-box in idim
+    // proc can appear twice in list if touches in both directions
+    // 2nd add-to-list checks to ensure each proc appears exactly once
+
+    noverlap = 0;
+    iswap = 2*idim;
+    n = nsendproc[iswap];
+    for (i = 0; i < n; i++) {
+      proc = sendproc[iswap][i];
+      if (proc == me) continue;
+      if ((this->*box_touch)(proc,idim,0)) {
+        if (noverlap == maxoverlap) {
+          maxoverlap += DELTA_PROCS;
+          memory->grow(overlap,maxoverlap,"comm:overlap");
+        }
+        overlap[noverlap++] = proc;
+      }
+    }
+    noverlap1 = noverlap;
+    iswap = 2*idim+1;
+    n = nsendproc[iswap];
+
+    MPI_Barrier(world);
+
+    for (i = 0; i < n; i++) {
+      proc = sendproc[iswap][i];
+      if (proc == me) continue;
+      if ((this->*box_touch)(proc,idim,1)) {
+        for (j = 0; j < noverlap1; j++)
+          if (overlap[j] == proc) break;
+        if (j < noverlap1) continue;
+        if (noverlap == maxoverlap) {
+          maxoverlap += DELTA_PROCS;
+          memory->grow(overlap,maxoverlap,"comm:overlap");
+        }
+        overlap[noverlap++] = proc;
+      }
+    }
+
+    MPI_Barrier(world);
+
+    // reallocate exchproc and exchnum if needed based on noverlap
+
+    if (noverlap > nexchprocmax[idim]) {
+      while (nexchprocmax[idim] < noverlap) nexchprocmax[idim] += DELTA_PROCS;
+      delete [] exchproc[idim];
+      exchproc[idim] = new int[nexchprocmax[idim]];
+      delete [] exchnum[idim];
+      exchnum[idim] = new int[nexchprocmax[idim]];
+    }
+
+    nexchproc[idim] = noverlap;
+    for (i = 0; i < noverlap; i++) exchproc[idim][i] = overlap[i];
+  }
+
+  // reset sendproc/etc to 0 if cut is really 0.0
+
+  if (cutzero) {
+    for (i = 0; i < nswap; i++) {
+      nsendproc[i] = nrecvproc[i] =
+        sendother[i] = recvother[i] = sendself[i] = 0;
+    }
+  }
+
+  // reallocate MPI Requests as needed
+
+  int nmax = 0;
+  for (i = 0; i < nswap; i++) nmax = MAX(nmax,nprocmax[i]);
+  for (i = 0; i < dimension; i++) nmax = MAX(nmax,nexchprocmax[i]);
+  if (nmax > maxrequest) {
+    maxrequest = nmax;
+    delete [] requests;
+    requests = new MPI_Request[maxrequest];
+  }
+}
+
+/**
+  * exchange: move atoms to correct processors
+  * atoms exchanged with procs that touch sub-box in each of 3 dims
+  * send out atoms that have left my box, receive ones entering my box
+  * atoms will be lost if not inside a touching proc's box
+  *   can happen if atom moves outside of non-periodic boundary
+  *   or if atom moves more than one proc away
+  * this routine called before every reneighboring
+  * for triclinic, atoms must be in lamda coords (0-1) before exchange is called
+  */
+
+void CommStaggered::exchange()
+{
+  if (layout != Comm::LAYOUT_STAGGERED) {
+    CommTiled::exchange();
+    return;
+  }
+  int i,m,nexch,nsend,nrecv,nlocal,proc,offset;
+  double lo,hi,value;
+  double **x;
+  AtomVec *avec = atom->avec;
+
+  // clear global->local map for owned and ghost atoms
+  // b/c atoms migrate to new procs in exchange() and
+  //   new ghosts are created in borders()
+  // map_set() is done at end of borders()
+  // clear ghost count and any ghost bonus data internal to AtomVec
+
+  if (map_style != Atom::MAP_NONE) atom->map_clear();
+  atom->nghost = 0;
+  atom->avec->clear_bonus();
+
+  // ensure send buf has extra space for a single atom
+  // only need to reset if a fix can dynamically add to size of single atom
+
+  if (maxexchange_fix_dynamic) {
+    init_exchange();
+    if (bufextra > bufextra_max) {
+      grow_send(maxsend+bufextra,2);
+      bufextra = bufextra_max;
+    }
+  }
+
+  // domain properties used in exchange method and methods it calls
+  // subbox bounds for orthogonal or triclinic
+
+  if (triclinic == 0) {
+    prd = domain->prd;
+    boxlo = domain->boxlo;
+    boxhi = domain->boxhi;
+    sublo = domain->sublo;
+    subhi = domain->subhi;
+  } else {
+    prd = domain->prd_lamda;
+    boxlo = domain->boxlo_lamda;
+    boxhi = domain->boxhi_lamda;
+    sublo = domain->sublo_lamda;
+    subhi = domain->subhi_lamda;
+  }
+
+  // loop over dimensions
+
+  dimension = domain->dimension;
+
+  ///> @todo-optimize
+  ///>       Loop over dimensions starting with layers for comm_style = staggered?
+  ///>       Could cause bugs for brick functions.
+  for (int dim = 0; dim < dimension; dim++) {
+
+    // fill buffer with atoms leaving my box, using < and >=
+    // when atom is deleted, fill it in with last atom
+
+    x = atom->x;
+    lo = sublo[dim];
+    hi = subhi[dim];
+    nlocal = atom->nlocal;
+    i = nsend = 0;
+
+    while (i < nlocal) {
+      if (x[i][dim] < lo || x[i][dim] >= hi) {
+        if (nsend > maxsend) grow_send(nsend,1);
+        proc = (this->*point_drop)(dim,x[i]);
+        if (proc != me) {
+          buf_send[nsend++] = proc;
+          nsend += avec->pack_exchange(i,&buf_send[nsend]);
+        } else {
+          // DEBUG statment
+          // error->warning(FLERR,"Losing atom in CommStaggered::exchange() send, "
+          //               "likely bad dynamics");
+        }
+        avec->copy(nlocal-1,i,1);
+        nlocal--;
+      } else i++;
+    }
+    atom->nlocal = nlocal;
+
+    // send and recv atoms from neighbor procs that touch my sub-box in dim
+    // no send/recv with self
+    // send size of message first
+    // receiver may receive multiple messages, realloc buf_recv if needed
+
+    nexch = nexchproc[dim];
+    if (!nexch) continue;
+
+    for (m = 0; m < nexch; m++) {
+      MPI_Irecv(&exchnum[dim][m],1,MPI_INT,exchproc[dim][m],2*dim,world,&requests[m]);
+    }
+    for (m = 0; m < nexch; m++) {
+      MPI_Send(&nsend,1,MPI_INT,exchproc[dim][m],2*dim,world);
+    }
+    MPI_Waitall(nexch,requests,MPI_STATUS_IGNORE);
+
+    nrecv = 0;
+    for (m = 0; m < nexch; m++) nrecv += exchnum[dim][m];
+    if (nrecv > maxrecv) grow_recv(nrecv);
+
+    offset = 0;
+    for (m = 0; m < nexch; m++) {
+      MPI_Irecv(&buf_recv[offset],exchnum[dim][m],MPI_DOUBLE,exchproc[dim][m],2*dim+1,world,&requests[m]); ///>@debug count may be zero
+      offset += exchnum[dim][m];
+    }
+    for (m = 0; m < nexch; m++) {
+      MPI_Send(buf_send,nsend,MPI_DOUBLE,exchproc[dim][m],2*dim+1,world); ///>@debug count may be zero
+    }
+    MPI_Waitall(nexch,requests,MPI_STATUS_IGNORE);
+
+    // check incoming atoms to see if I own it and they are in my box
+    // if so, add to my list
+    // box check is only for this dimension,
+    //   atom may be passed to another proc in later dims
+
+    m = 0;
+    while (m < nrecv) {
+      proc = static_cast<int> (buf_recv[m++]);
+      if (proc == me) {
+        value = buf_recv[m+dim+1];
+        if (value >= lo && value < hi) {
+          m += avec->unpack_exchange(&buf_recv[m]);
+          continue;
+        } else {
+          // DEBUG statment
+          // error->warning(FLERR,"Losing atom in CommStaggered::exchange() recv");
+        }
+      }
+      m += static_cast<int> (buf_recv[m]);
+    }
+  }
+
+  if (atom->firstgroupname) atom->first_reorder();
+}
+
+/**
+  * Determine overlap list of Noverlap procs the lo/hi box overlaps.
+  * overlap = non-zero area in common between box and proc sub-domain.
+  * Recursive method for traversing an RCB tree of cuts.
+  * No need to split lo/hi box as recurse b/c OK if box extends outside RCB box.
+  * @todo-optimize
+  *       Rewrite and consider the fact, that the requested neighbours are in neighbouring layers, rows, cells
+  * @param[in] lo left box boundaries in spatial box coordinates
+  * @param[in] hi right box boundaries in spatial box coordinates
+  * @note Writes overlaping processors to array overlap.
+  *       The number of processors in this array is noverlap.
+  * @param[out] indexme index of own processor in overlap list
+  */
+
+void CommStaggered::box_drop_staggered(int /*idim*/, double *lo, double *hi, int &indexme)
+{
+  int layer_lo, layer_hi, layer_i;
+  int row_lo, row_hi, row_i;
+  int cell_lo, cell_hi, cell_i;
+  int rank_overlap;
+
+  // calculate layer range
+  box_drop_1d(lo[staggered2spatial[0]], hi[staggered2spatial[0]], layer_splits, n_layers,
+             staggered2spatial[0], layer_lo, layer_hi);
+  for (int i_layer=layer_lo; i_layer<=layer_hi; i_layer++) {
+    // calculate row range
+    box_drop_1d(lo[staggered2spatial[1]], hi[staggered2spatial[1]], row_splits[i_layer], n_rows,
+                staggered2spatial[1], row_lo, row_hi);
+
+    for (int i_row=row_lo; i_row<=row_hi; i_row++) {
+      // calculate cell range
+      box_drop_1d(lo[staggered2spatial[2]], hi[staggered2spatial[2]], cell_splits[i_layer][i_row],
+                  n_cells, staggered2spatial[2], cell_lo, cell_hi);
+
+      for (int i_cell=cell_lo; i_cell<=cell_hi; i_cell++) {
+        // this cell overlaps with the given box
+        rank_overlap = staggered_grid2proc[i_layer][i_row][i_cell];
+
+        // allocate more memory if required
+        if (noverlap == maxoverlap) {
+          maxoverlap += DELTA_PROCS;
+          memory->grow(overlap,maxoverlap,"comm:overlap");
+        }
+
+        if (rank_overlap == me) indexme = noverlap;
+        overlap[noverlap++] = rank_overlap;
+      }
+    }
+  }
+}
+
+/**
+  * @brief return other box owned by proc as lo/hi corner pts
+  * @param[in] proc rank of a processor
+  * @param[out] lo low boundaries of processor in box units
+  * @param[out] hi high boundaries of processor in box units
+  */
+
+void CommStaggered::box_other_staggered(int /*idim*/, int /*idir*/, int proc, double *lo, double *hi)
+{
+  int * loc = staggered_proc2grid[proc];
+
+  lo[staggered2spatial[0]] = boxlo[staggered2spatial[0]] + prd[staggered2spatial[0]]*layer_splits[loc[0]];
+  if (loc[0]+1 == n_layers) hi[staggered2spatial[0]] = boxhi[staggered2spatial[0]];
+  else hi[staggered2spatial[0]] = boxlo[staggered2spatial[0]] + prd[staggered2spatial[0]]*layer_splits[loc[0]+1];
+
+  lo[staggered2spatial[1]] = boxlo[staggered2spatial[1]] + prd[staggered2spatial[1]]*row_splits[loc[0]][loc[1]];
+  if (loc[1]+1 == n_rows) hi[staggered2spatial[1]] = boxhi[staggered2spatial[1]];
+  else hi[staggered2spatial[1]] = boxlo[staggered2spatial[1]] + prd[staggered2spatial[1]]*row_splits[loc[0]][loc[1]+1];
+
+  lo[staggered2spatial[2]] = boxlo[staggered2spatial[2]] + prd[staggered2spatial[2]]*cell_splits[loc[0]][loc[1]][loc[2]];
+  if (loc[2]+1 == n_cells) hi[staggered2spatial[2]] = boxhi[staggered2spatial[2]];
+  else hi[staggered2spatial[2]] = boxlo[staggered2spatial[2]] + prd[staggered2spatial[2]]*cell_splits[loc[0]][loc[1]][loc[2]+1];
+
+}
+
+/**
+  * @brief return other box owned by proc as lo/hi corner pts
+  * @param[in] proc rank of a processor
+  * @param[out] lo low boundaries of processor in [0,1] units
+  * @param[out] hi high boundaries of processor in [0,1] units
+  */
+
+void CommStaggered::box_other_mysplit(int proc, double *lo, double *hi)
+{
+  int * loc = staggered_proc2grid[proc];
+
+  lo[staggered2spatial[0]] = layer_splits[loc[0]];
+  hi[staggered2spatial[0]] = layer_splits[loc[0]+1];
+
+  lo[staggered2spatial[1]] = row_splits[loc[0]][loc[1]];
+  hi[staggered2spatial[1]] = row_splits[loc[0]][loc[1]+1];
+
+  lo[staggered2spatial[2]] = cell_splits[loc[0]][loc[1]][loc[2]];
+  hi[staggered2spatial[2]] = cell_splits[loc[0]][loc[1]][loc[2]+1];
+}
+
+/**
+  * return 1 if proc's box touches me, else 0
+  * @param[in] proc other processor
+  * @param[in] idim dimension in which the touch is tested
+  * @param[in] idir direction in which the touch is tested (0 = left of my processor, 1 = right)
+  * @return 1 if neighbous in idim and idir, 0 otherwise
+  */
+
+int CommStaggered::box_touch_staggered(int proc, int idim, int idir)
+{
+  // use staggered grid notation
+  idim = spatial2staggered[idim];
+
+  // sending to left
+  // only touches if proc hi = my lo, or if proc hi = boxhi and my lo = boxlo
+
+  if (idir == 0) {
+    if (staggered_proc2grid[proc][idim] + 1 == staggered_myloc[idim])
+      return 1;
+    else if (staggered_proc2grid[proc][idim] == staggered_procgrid[idim] - 1 &&
+             staggered_myloc[idim] == 0)
+      return 1;
+
+  // sending to right
+  // only touches if proc lo = my hi, or if proc lo = boxlo and my hi = boxhi
+
+  } else {
+    if (staggered_proc2grid[proc][idim] == staggered_myloc[idim] + 1)
+      return 1;
+    else if (staggered_proc2grid[proc][idim] == 0 &&
+             staggered_myloc[idim] == staggered_procgrid[idim] -1)
+      return 1;
+  }
+
+  return 0;
+}
+
+/**
+  * @brief Determine which proc owns point x.
+  * Drop point into staggered mesh.
+  * Sending starts with increasing idim.
+  * Smaller dimensions that idim are already exchanged.
+  * @todo-optimize
+  *       Rewrite function since it depends on the tiled communication routine.
+  *       When starting with communictation in layer direction, on can simply
+  *       check only the neighbouring layer and so on.
+  * @param[in] idim dimension in which the point is outside
+  * @param[in] x position of point
+  */
+
+int CommStaggered::point_drop_staggered(int idim, double *x)
+{
+  double xnew[3];
+  xnew[0] = x[0]; xnew[1] = x[1]; xnew[2] = x[2];
+
+  // Ensure that the target processor is a neighbour.
+  // idim = 0
+  // Set xnew to own boundaries if x is outside in dimensions 1 and 2.
+  // idim = 1
+  // Set xnew to own boundaries if x is outside in dimensions 2.
+  // idim = 2
+  // Do not change xnew.
+
+
+  if (idim == 0) {
+    if (xnew[1] < sublo[1] || xnew[1] > subhi[1]) {
+      if (closer_subbox_edge(1,x)) xnew[1] = subhi[1];
+      else xnew[1] = sublo[1];
+    }
+  }
+  if (idim <= 1) {
+    if (xnew[2] < sublo[2] || xnew[2] > subhi[2]) {
+      if (closer_subbox_edge(2,x)) xnew[2] = subhi[2];
+      else xnew[2] = sublo[2];
+    }
+  }
+
+  int proc = point_drop_staggered_recurse(xnew);
+  double proc_lo[3], proc_hi[3];
+  if (proc == me) return me;
+
+  // x communication
+  if (idim == 0) {
+    box_other_mysplit(proc, proc_lo, proc_hi);
+
+    int done = 1;
+    //  proc y lo == me y hi
+    if (proc_lo[1] == mysplit[1][1]) {
+      // proc is right of me in y
+      xnew[1] -= EPSILON * (subhi[1]-sublo[1]);
+      // move atom inside of own proc
+      // -> atom is not send to this neighbour (in this step)
+      // atom could be sent in y communication
+      done = 0;
+      // -> drop point again to find different processor
+    }
+    if (proc_lo[2] == mysplit[2][1]) {
+      // proc is right of me in z
+      xnew[2] -= EPSILON * (subhi[2]-sublo[2]);
+      // change xnew to inside in z
+      done = 0;
+      // -> drop point again
+    }
+    if (!done) {
+      proc = point_drop_staggered_recurse(xnew);
+      box_other_mysplit(proc, proc_lo, proc_hi);
+      done = 1;
+      // proc y lo == me y hi
+      // -> proc is right of me in y
+      if (proc_lo[1] == mysplit[1][1]) {
+        // set atom inside in y
+        xnew[1] -= EPSILON * (subhi[1]-sublo[1]);
+        // drop again
+        done = 0;
+      }
+      // proc z lo == me z hi
+      // -> proc is right of me in z
+      if (proc_lo[2] == mysplit[2][1]) {
+        // set atom inside in z
+        xnew[2] -= EPSILON * (subhi[2]-sublo[2]);
+        // drop again
+        done = 0;
+      }
+      if (!done) proc = point_drop_staggered_recurse(xnew);
+      ///> ->The atom is shifted inside of the own box in y and z if required to find a neighbour in x direction
+    }
+  } else if (idim == 1) {
+    // proc z lo == me z hi
+    // -> proc is right of me in z
+    box_other_mysplit(proc, proc_lo, proc_hi);
+    if (proc_lo[2] == mysplit[2][1]) {
+      xnew[2] -= EPSILON * (subhi[2]-sublo[2]);
+      proc = point_drop_staggered_recurse(xnew);
+    }
+  }
+
+  return proc;
+}
+
+/**
+  * @brief Drop point in staggered mesh in dimension dim.
+  * @note Do not use for box drop since the boundary conditions differ.
+  *       A point is inside for p in [splitlo, splithi).
+  *       A box point is inside for p in (splitlo, splithi).
+  * @param[in] value to sort into staggered mesh in box coordinatos
+  * @param[in] splitlist list of splits e.g. layer_splits
+  * @param[in] listlen length of splitlist
+  * @param[in] dim spatial dimension of value
+  * @return i in staggered grid in the given dimension
+  */
+
+int CommStaggered::point_drop_1d(double value, double * splitlist, int listlen, int dim)
+{
+  double cut;
+  int procmid;
+
+  int proclower = 0;
+  int procupper = listlen -1;
+  while (proclower != procupper) {
+    procmid = proclower + (procupper - proclower) / 2 + 1;
+    cut = boxlo[dim] + prd[dim] * splitlist[procmid];
+    if (value < cut) procupper = procmid -1;
+    else proclower = procmid;
+  }
+  return proclower;
+}
+
+/**
+  * @brief Drop 1d box in staggered mesh in dimension dim.
+  * @note Do not use for point drop since the boundary conditions differ.
+  *       A point is inside for p in [splitlo, splithi).
+  *       A box point is inside for p in (splitlo, splithi).
+  * @param[in] lo lower value to sort into staggered mesh in box coordinatos
+  * @param[in] hi lower value to sort into staggered mesh in box coordinatos
+  * @param[in] splitlist list of splits e.g. layer_splits
+  * @param[in] listlen length of splitlist
+  * @param[in] dim spatial dimension of value
+  * @param[out] rtn_lo processor i in staggered grid in the given dimension of value lo
+  * @param[out] rtn_hi processor i in staggered grid in the given dimension of value hi
+  */
+
+void CommStaggered::box_drop_1d(double lo, double hi, double * splitlist, int listlen, int dim, int & rtn_lo, int & rtn_hi)
+{
+  double cut;
+  int procmid, proclower, procupper;
+
+  // drop lo
+  proclower = 0;
+  procupper = listlen -1;
+  while (proclower != procupper) {
+    procmid = proclower + (procupper - proclower) / 2 + 1;
+    cut = boxlo[dim] + prd[dim] * splitlist[procmid];
+    if (lo < cut) procupper = procmid -1;
+    else proclower = procmid;
+  }
+  rtn_lo = proclower;
+
+  // drop hi
+  // hi > lo -> rtn_hi >= rtn_lo
+  procupper = listlen -1;
+  while (proclower != procupper) {
+    procmid = proclower + (procupper - proclower) / 2 + 1;
+    cut = boxlo[dim] + prd[dim] * splitlist[procmid];
+    if (hi > cut ) proclower = procmid;
+    else procupper = procmid -1;
+  }
+  rtn_hi = proclower;
+}
+
+/**
+  * drop in staggered mesh
+  * @param[in] x point in box coordinates
+  * @return rank of processor
+  */
+
+int CommStaggered::point_drop_staggered_recurse(double *x)
+{
+  int i_layer, i_row, i_cell;
+  // find layer
+  i_layer = point_drop_1d(x[staggered2spatial[0]], layer_splits,                n_layers, staggered2spatial[0]);
+  i_row   = point_drop_1d(x[staggered2spatial[1]], row_splits[i_layer],         n_rows,   staggered2spatial[1]);
+  i_cell  = point_drop_1d(x[staggered2spatial[2]], cell_splits[i_layer][i_row], n_cells,  staggered2spatial[2]);
+
+  return staggered_grid2proc[i_layer][i_row][i_cell];
+}
+
+/**
+  * probably wrong line: if RCB decomp exists and just changed, gather needed global RCB info
+  *
+  * required input: procgrid, myloc, spatial2staggered, staggered2spatial, grid2proc
+  */
+
+void CommStaggered::coord2proc_setup()
+{
+  if (!staggerednew) return;
+  staggerednew = 0;
+
+  // gather lower boundaries of all processors
+  double gatherbuffer[nprocs*3];
+  gatherbuffer[me*3+spatial2staggered[0]] = mysplit[0][0];
+  gatherbuffer[me*3+spatial2staggered[1]] = mysplit[1][0];
+  gatherbuffer[me*3+spatial2staggered[2]] = mysplit[2][0];
+  MPI_Allgather(MPI_IN_PLACE,3,MPI_DOUBLE,gatherbuffer,3,MPI_DOUBLE,world);
+
+  // store splits
+  for (int il = 0; il < n_layers; il++) {
+    layer_splits[il] = gatherbuffer[staggered_grid2proc[il][0][0]*3+0];
+    for (int ir = 0; ir < n_rows; ir++) {
+      row_splits[il][ir] = gatherbuffer[staggered_grid2proc[il][ir][0]*3+1];
+      for (int ic = 0; ic < n_cells; ic++) {
+        cell_splits[il][ir][ic] = gatherbuffer[staggered_grid2proc[il][ir][ic]*3+2];
+      }
+      cell_splits[il][ir][n_cells] = 1;
+    }
+    row_splits[il][n_rows] = 1;
+  }
+  layer_splits[n_layers] = 1;
+}
+
+/**
+  * Determine which proc owns atom with coord x[3] based on current decomp.
+  * x will be in box (orthogonal) or lamda coords (triclinic).
+  * if layout = UNIFORM or NONUNIFORM, invoke parent method.
+  * if layout = STAGGERED, use point_drop_recurse().
+  * @return owning proc ID, ignore igx,igy,igz
+  */
+
+int CommStaggered::coord2proc(double *x, int &igx, int &igy, int &igz)
+{
+  if (layout != Comm::LAYOUT_STAGGERED) return Comm::coord2proc(x,igx,igy,igz);
+  return point_drop_staggered_recurse(x);
+}
+
+/* ----------------------------------------------------------------------
+   return # of bytes of allocated memory
+------------------------------------------------------------------------- */
+
+double CommStaggered::memory_usage()
+{
+  double bytes = 0;
+  return bytes;
+}
diff --git a/src/comm_staggered.h b/src/comm_staggered.h
new file mode 100644
index 0000000000..7b0f46392a
--- /dev/null
+++ b/src/comm_staggered.h
@@ -0,0 +1,68 @@
+/* -*- c++ -*- ----------------------------------------------------------
+   LAMMPS - Large-scale Atomic/Molecular Massively Parallel Simulator
+   https://www.lammps.org/, Sandia National Laboratories
+   LAMMPS development team: developers@lammps.org
+
+   Copyright (2003) Sandia Corporation.  Under the terms of Contract
+   DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains
+   certain rights in this software.  This software is distributed under
+   the GNU General Public License.
+
+   See the README file in the top-level LAMMPS directory.
+------------------------------------------------------------------------- */
+
+#ifndef LMP_COMM_STAGGERED_H
+#define LMP_COMM_STAGGERED_H
+
+#include "comm.h"
+#include "comm_tiled.h"
+
+namespace LAMMPS_NS {
+
+class CommStaggered : public CommTiled {
+ public:
+  CommStaggered(class LAMMPS *, class Comm *, char * arg);
+
+  ~CommStaggered() override;
+
+  void setup() override;                // setup comm pattern
+  void exchange() override;             // move atoms to new procs
+
+  void coord2proc_setup() override;
+  int coord2proc(double *, int &, int &, int &) override;
+
+  double memory_usage() override;
+
+ private:
+  double * layer_splits;                // store splits for layers
+  double ** row_splits;                 // store splits for rows
+  double *** cell_splits;               // store splits for cells
+
+  void init_buffers_staggered();
+
+  // box drop and other functions
+  void box_drop_1d(double, double, double *, int , int , int &, int &);
+  int point_drop_1d(double, double *, int, int);
+
+  typedef void (CommStaggered::*BoxDropPtr)(int, double *, double *, int &);
+  BoxDropPtr box_drop;
+  void box_drop_staggered(int, double *, double *, int &);
+
+  typedef void (CommStaggered::*BoxOtherPtr)(int, int, int, double *, double *);
+  BoxOtherPtr box_other;
+  void box_other_staggered(int, int, int, double *, double *);
+  void box_other_mysplit(int, double *, double *);
+
+  typedef int (CommStaggered::*BoxTouchPtr)(int, int, int);
+  BoxTouchPtr box_touch;
+  int box_touch_staggered(int, int, int);
+
+  typedef int (CommStaggered::*PointDropPtr)(int, double *);
+  PointDropPtr point_drop;
+  int point_drop_staggered(int, double *);
+  int point_drop_staggered_recurse(double *);
+};
+
+}    // namespace LAMMPS_NS
+
+#endif
diff --git a/src/domain.cpp b/src/domain.cpp
index b06529e56a..ddaa3ba5ea 100644
--- a/src/domain.cpp
+++ b/src/domain.cpp
@@ -324,7 +324,7 @@ void Domain::set_global_box()
 
 void Domain::set_lamda_box()
 {
-  if (comm->layout != Comm::LAYOUT_TILED) {
+  if (comm->layout != Comm::LAYOUT_TILED && comm->layout != Comm::LAYOUT_STAGGERED) {
     int *myloc = comm->myloc;
     double *xsplit = comm->xsplit;
     double *ysplit = comm->ysplit;
@@ -361,7 +361,7 @@ void Domain::set_local_box()
 {
   if (triclinic) return;
 
-  if (comm->layout != Comm::LAYOUT_TILED) {
+  if (comm->layout != Comm::LAYOUT_TILED && comm->layout != Comm::LAYOUT_STAGGERED) {
     int *myloc = comm->myloc;
     int *procgrid = comm->procgrid;
     double *xsplit = comm->xsplit;
diff --git a/src/input.cpp b/src/input.cpp
index d8d430693e..b7e462356e 100644
--- a/src/input.cpp
+++ b/src/input.cpp
@@ -21,6 +21,7 @@
 #include "bond.h"
 #include "comm.h"
 #include "comm_brick.h"
+#include "comm_staggered.h"
 #include "comm_tiled.h"
 #include "command.h"
 #include "compute.h"
@@ -1455,6 +1456,12 @@ void Input::comm_style()
     if (lmp->kokkos) comm = new CommTiledKokkos(lmp,oldcomm);
     else comm = new CommTiled(lmp,oldcomm);
     delete oldcomm;
+  } else if (strcmp(arg[0],"staggered") == 0) {
+    if (narg < 2) error->all(FLERR,"Illegal comm_style staggered command");
+    Comm *oldcomm = comm;
+    if (lmp->kokkos) error->all(FLERR,"kokkos is not supported by CommStaggered");
+    else comm = new CommStaggered(lmp, oldcomm, arg[1]);
+    delete oldcomm;
   } else error->all(FLERR,"Unknown comm_style argument: {}", arg[0]);
 }
 
diff --git a/src/irregular.cpp b/src/irregular.cpp
index f16669e5be..dc45d1fa2b 100644
--- a/src/irregular.cpp
+++ b/src/irregular.cpp
@@ -226,10 +226,11 @@ void Irregular::migrate_atoms(int sortflag, int preassign, int *procassign)
 
 int Irregular::migrate_check()
 {
-  // migrate required if comm layout is tiled
+  // migrate required if comm layout is tiled or staggered
   // cannot use myloc[] logic below
 
   if (comm->layout == Comm::LAYOUT_TILED) return 1;
+  if (comm->layout == Comm::LAYOUT_STAGGERED) return 1;
 
   // subbox bounds for orthogonal or triclinic box
 
diff --git a/src/library.cpp b/src/library.cpp
index 3aeb0dfef5..64778b1052 100644
--- a/src/library.cpp
+++ b/src/library.cpp
@@ -1412,9 +1412,9 @@ internally by the :doc:`Fortran interface <Fortran>` and are not likely to be us
    * - world_size
      - Number of ranks on LAMMPS' world communicator (aka comm->nprocs)
    * - comm_style
-     - communication style (0 = BRICK, 1 = TILED)
+     - communication style (0 = BRICK, 1 = TILED, 2 = STAGGERED)
    * - comm_layout
-     - communication layout (0 = LAYOUT_UNIFORM, 1 = LAYOUT_NONUNIFORM, 2 = LAYOUT_TILED)
+     - communication layout (0 = LAYOUT_UNIFORM, 1 = LAYOUT_NONUNIFORM, 2 = LAYOUT_TILED, 3 = LAYOUT_STAGGERED)
    * - comm_mode
      - communication mode (0 = SINGLE, 1 = MULTI, 2 = MULTIOLD)
    * - ghost_velocity
